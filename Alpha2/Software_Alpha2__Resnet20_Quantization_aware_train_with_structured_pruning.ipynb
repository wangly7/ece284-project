{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "ResNet_Cifar(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter      \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 256\n",
    "model_name = \"Resnet20_quant_structure_pruning\"\n",
    "model = resnet20_quant()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [80, 120]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 7853/10000 (79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/{}/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH.format(model_name))\n",
    "\n",
    "# Apply pruning structure to model before loading checkpoint\n",
    "import torch.nn.utils.prune as prune\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, QuantConv2d):\n",
    "        prune.ln_structured(module, name='weight', amount=0.8, dim=0, n=2)\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prune all the QuantConv2D layers' 90% weights with 1) unstructured, and 2) structured manner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aea7b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 80% weights in layer1.0.conv1\n",
      "Pruning 80% weights in layer1.0.conv2\n",
      "Pruning 80% weights in layer1.1.conv1\n",
      "Pruning 80% weights in layer1.1.conv2\n",
      "Pruning 80% weights in layer1.2.conv1\n",
      "Pruning 80% weights in layer1.2.conv2\n",
      "Pruning 80% weights in layer2.0.conv1\n",
      "Pruning 80% weights in layer2.0.conv2\n",
      "Pruning 80% weights in layer2.0.downsample.0\n",
      "Pruning 80% weights in layer2.1.conv1\n",
      "Pruning 80% weights in layer2.1.conv2\n",
      "Pruning 80% weights in layer2.2.conv1\n",
      "Pruning 80% weights in layer2.2.conv2\n",
      "Pruning 80% weights in layer3.0.conv1\n",
      "Pruning 80% weights in layer3.0.conv2\n",
      "Pruning 80% weights in layer3.0.downsample.0\n",
      "Pruning 80% weights in layer3.1.conv1\n",
      "Pruning 80% weights in layer3.1.conv2\n",
      "Pruning 80% weights in layer3.2.conv1\n",
      "Pruning 80% weights in layer3.2.conv2\n"
     ]
    }
   ],
   "source": [
    "# Structured pruning with 80% sparsity\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, QuantConv2d):\n",
    "        print(\"Pruning 80% weights in {}\".format(name))\n",
    "        prune.ln_structured(module, name='weight', amount=0.8, dim=0, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8aedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a QuantConv2d layer in the model (e.g., layer3[2].conv2)\n",
    "print(list(model.layer3[2].conv2.named_parameters())) # check whether there is mask, weight_org, ...\n",
    "print(model.layer3[2].conv2.weight) # check whether there are many zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.7969, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### Check sparsity ###\n",
    "mask1 = model.layer3[2].conv2.weight_mask\n",
    "sparsity_mask1 = (mask1 == 0).sum() / mask1.nelement()\n",
    "\n",
    "print(\"Sparsity level: \", sparsity_mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acquired-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 7853/10000 (79%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check accuracy after pruning\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/196]\tTime 4.386 (4.386)\tData 4.262 (4.262)\tLoss 2.6154 (2.6154)\tPrec 9.766% (9.766%)\n",
      "Epoch: [0][100/196]\tTime 0.020 (0.064)\tData 0.001 (0.043)\tLoss 1.6307 (1.9228)\tPrec 33.984% (26.350%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.572 (3.572)\tLoss 1.6657 (1.6657)\tPrec 37.891% (37.891%)\n",
      " * Prec 38.640% \n",
      "best acc: 38.640000\n",
      "Epoch: [1][0/196]\tTime 4.335 (4.335)\tData 4.313 (4.313)\tLoss 1.5175 (1.5175)\tPrec 45.703% (45.703%)\n",
      "Epoch: [1][100/196]\tTime 0.020 (0.063)\tData 0.001 (0.043)\tLoss 1.4234 (1.4850)\tPrec 49.219% (44.214%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.708 (3.708)\tLoss 2.1036 (2.1036)\tPrec 28.125% (28.125%)\n",
      " * Prec 36.670% \n",
      "best acc: 38.640000\n",
      "Epoch: [2][0/196]\tTime 4.418 (4.418)\tData 4.399 (4.399)\tLoss 1.3404 (1.3404)\tPrec 51.562% (51.562%)\n",
      "Epoch: [2][100/196]\tTime 0.020 (0.063)\tData 0.001 (0.044)\tLoss 1.3617 (1.3272)\tPrec 45.703% (51.381%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.646 (3.646)\tLoss 1.6781 (1.6781)\tPrec 41.406% (41.406%)\n",
      " * Prec 45.290% \n",
      "best acc: 45.290000\n",
      "Epoch: [3][0/196]\tTime 4.406 (4.406)\tData 4.381 (4.381)\tLoss 1.2023 (1.2023)\tPrec 58.203% (58.203%)\n",
      "Epoch: [3][100/196]\tTime 0.019 (0.064)\tData 0.000 (0.044)\tLoss 1.2618 (1.2328)\tPrec 57.812% (55.353%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.818 (3.818)\tLoss 1.3940 (1.3940)\tPrec 50.781% (50.781%)\n",
      " * Prec 51.640% \n",
      "best acc: 51.640000\n",
      "Epoch: [4][0/196]\tTime 4.516 (4.516)\tData 4.496 (4.496)\tLoss 1.2751 (1.2751)\tPrec 50.391% (50.391%)\n",
      "Epoch: [4][100/196]\tTime 0.019 (0.067)\tData 0.001 (0.045)\tLoss 1.0966 (1.1702)\tPrec 59.375% (57.580%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.780 (3.780)\tLoss 1.3208 (1.3208)\tPrec 52.344% (52.344%)\n",
      " * Prec 55.600% \n",
      "best acc: 55.600000\n",
      "Epoch: [5][0/196]\tTime 4.331 (4.331)\tData 4.310 (4.310)\tLoss 1.1476 (1.1476)\tPrec 60.938% (60.938%)\n",
      "Epoch: [5][100/196]\tTime 0.020 (0.062)\tData 0.001 (0.043)\tLoss 1.1407 (1.1446)\tPrec 57.422% (58.683%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.545 (3.545)\tLoss 1.5226 (1.5226)\tPrec 53.125% (53.125%)\n",
      " * Prec 51.240% \n",
      "best acc: 55.600000\n",
      "Epoch: [6][0/196]\tTime 4.438 (4.438)\tData 4.420 (4.420)\tLoss 1.0829 (1.0829)\tPrec 57.031% (57.031%)\n",
      "Epoch: [6][100/196]\tTime 0.020 (0.064)\tData 0.001 (0.044)\tLoss 1.0562 (1.0960)\tPrec 59.766% (60.512%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.609 (3.609)\tLoss 1.1382 (1.1382)\tPrec 55.078% (55.078%)\n",
      " * Prec 58.290% \n",
      "best acc: 58.290000\n",
      "Epoch: [7][0/196]\tTime 4.296 (4.296)\tData 4.270 (4.270)\tLoss 1.0240 (1.0240)\tPrec 64.062% (64.062%)\n",
      "Epoch: [7][100/196]\tTime 0.019 (0.063)\tData 0.001 (0.043)\tLoss 1.0021 (1.0654)\tPrec 65.234% (61.823%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.748 (3.748)\tLoss 1.2732 (1.2732)\tPrec 56.250% (56.250%)\n",
      " * Prec 52.170% \n",
      "best acc: 58.290000\n",
      "Epoch: [8][0/196]\tTime 4.372 (4.372)\tData 4.349 (4.349)\tLoss 1.0962 (1.0962)\tPrec 62.500% (62.500%)\n",
      "Epoch: [8][100/196]\tTime 0.020 (0.063)\tData 0.001 (0.044)\tLoss 1.1104 (1.0301)\tPrec 60.156% (63.204%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.754 (3.754)\tLoss 2.9043 (2.9043)\tPrec 34.375% (34.375%)\n",
      " * Prec 35.710% \n",
      "best acc: 58.290000\n",
      "Epoch: [9][0/196]\tTime 4.297 (4.297)\tData 4.276 (4.276)\tLoss 1.1267 (1.1267)\tPrec 56.641% (56.641%)\n",
      "Epoch: [9][100/196]\tTime 0.020 (0.062)\tData 0.001 (0.043)\tLoss 0.9875 (1.0421)\tPrec 62.891% (62.740%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.672 (3.672)\tLoss 1.5672 (1.5672)\tPrec 49.219% (49.219%)\n",
      " * Prec 47.820% \n",
      "best acc: 58.290000\n",
      "Epoch: [10][0/196]\tTime 4.676 (4.676)\tData 4.652 (4.652)\tLoss 1.0323 (1.0323)\tPrec 60.547% (60.547%)\n",
      "Epoch: [10][100/196]\tTime 0.036 (0.086)\tData 0.001 (0.047)\tLoss 1.0420 (1.0053)\tPrec 63.672% (64.144%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.724 (3.724)\tLoss 1.0254 (1.0254)\tPrec 59.766% (59.766%)\n",
      " * Prec 64.080% \n",
      "best acc: 64.080000\n",
      "Epoch: [11][0/196]\tTime 4.486 (4.486)\tData 4.461 (4.461)\tLoss 1.0667 (1.0667)\tPrec 64.062% (64.062%)\n",
      "Epoch: [11][100/196]\tTime 0.036 (0.084)\tData 0.001 (0.045)\tLoss 0.9761 (0.9795)\tPrec 66.797% (65.571%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.868 (3.868)\tLoss 1.4209 (1.4209)\tPrec 52.734% (52.734%)\n",
      " * Prec 53.720% \n",
      "best acc: 64.080000\n",
      "Epoch: [12][0/196]\tTime 4.506 (4.506)\tData 4.481 (4.481)\tLoss 1.0270 (1.0270)\tPrec 64.844% (64.844%)\n",
      "Epoch: [12][100/196]\tTime 0.037 (0.082)\tData 0.001 (0.045)\tLoss 0.8626 (0.9498)\tPrec 69.922% (66.174%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.825 (3.825)\tLoss 1.1547 (1.1547)\tPrec 60.547% (60.547%)\n",
      " * Prec 60.890% \n",
      "best acc: 64.080000\n",
      "Epoch: [13][0/196]\tTime 4.449 (4.449)\tData 4.424 (4.424)\tLoss 0.8854 (0.8854)\tPrec 69.922% (69.922%)\n",
      "Epoch: [13][100/196]\tTime 0.056 (0.095)\tData 0.001 (0.044)\tLoss 0.9729 (0.9469)\tPrec 66.016% (66.236%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.829 (3.829)\tLoss 1.2502 (1.2502)\tPrec 60.938% (60.938%)\n",
      " * Prec 57.720% \n",
      "best acc: 64.080000\n",
      "Epoch: [14][0/196]\tTime 4.393 (4.393)\tData 4.361 (4.361)\tLoss 0.9314 (0.9314)\tPrec 66.406% (66.406%)\n",
      "Epoch: [14][100/196]\tTime 0.021 (0.093)\tData 0.001 (0.044)\tLoss 0.9344 (0.9348)\tPrec 68.359% (66.743%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.931 (3.931)\tLoss 1.0549 (1.0549)\tPrec 64.453% (64.453%)\n",
      " * Prec 63.690% \n",
      "best acc: 64.080000\n",
      "Epoch: [15][0/196]\tTime 4.531 (4.531)\tData 4.504 (4.504)\tLoss 0.9515 (0.9515)\tPrec 66.406% (66.406%)\n",
      "Epoch: [15][100/196]\tTime 0.022 (0.088)\tData 0.001 (0.045)\tLoss 0.8748 (0.9129)\tPrec 70.312% (67.505%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.007 (4.007)\tLoss 1.0057 (1.0057)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.730% \n",
      "best acc: 64.080000\n",
      "Epoch: [16][0/196]\tTime 4.444 (4.444)\tData 4.406 (4.406)\tLoss 0.7949 (0.7949)\tPrec 73.438% (73.438%)\n",
      "Epoch: [16][100/196]\tTime 0.020 (0.079)\tData 0.001 (0.044)\tLoss 0.8494 (0.8966)\tPrec 68.750% (68.441%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.843 (3.843)\tLoss 1.2365 (1.2365)\tPrec 59.375% (59.375%)\n",
      " * Prec 58.100% \n",
      "best acc: 64.080000\n",
      "Epoch: [17][0/196]\tTime 4.438 (4.438)\tData 4.411 (4.411)\tLoss 0.9241 (0.9241)\tPrec 67.578% (67.578%)\n",
      "Epoch: [17][100/196]\tTime 0.028 (0.080)\tData 0.001 (0.044)\tLoss 0.8623 (0.8894)\tPrec 67.578% (68.955%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 5.002 (5.002)\tLoss 1.5209 (1.5209)\tPrec 51.953% (51.953%)\n",
      " * Prec 54.010% \n",
      "best acc: 64.080000\n",
      "Epoch: [18][0/196]\tTime 5.983 (5.983)\tData 5.948 (5.948)\tLoss 0.9835 (0.9835)\tPrec 63.281% (63.281%)\n",
      "Epoch: [18][100/196]\tTime 0.030 (0.087)\tData 0.001 (0.060)\tLoss 0.8411 (0.8770)\tPrec 69.922% (69.299%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.928 (4.928)\tLoss 1.7820 (1.7820)\tPrec 50.781% (50.781%)\n",
      " * Prec 48.610% \n",
      "best acc: 64.080000\n",
      "Epoch: [19][0/196]\tTime 5.887 (5.887)\tData 5.860 (5.860)\tLoss 0.9041 (0.9041)\tPrec 65.625% (65.625%)\n",
      "Epoch: [19][100/196]\tTime 0.024 (0.084)\tData 0.001 (0.059)\tLoss 0.9082 (0.8706)\tPrec 66.797% (69.172%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.924 (4.924)\tLoss 1.2839 (1.2839)\tPrec 62.891% (62.891%)\n",
      " * Prec 57.020% \n",
      "best acc: 64.080000\n",
      "Epoch: [20][0/196]\tTime 5.939 (5.939)\tData 5.910 (5.910)\tLoss 0.8176 (0.8176)\tPrec 72.266% (72.266%)\n",
      "Epoch: [20][100/196]\tTime 0.025 (0.085)\tData 0.001 (0.059)\tLoss 0.7659 (0.8550)\tPrec 72.656% (69.841%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.980 (4.980)\tLoss 0.9423 (0.9423)\tPrec 67.578% (67.578%)\n",
      " * Prec 65.800% \n",
      "best acc: 65.800000\n",
      "Epoch: [21][0/196]\tTime 5.890 (5.890)\tData 5.866 (5.866)\tLoss 0.9054 (0.9054)\tPrec 67.969% (67.969%)\n",
      "Epoch: [21][100/196]\tTime 0.026 (0.084)\tData 0.001 (0.059)\tLoss 0.8058 (0.8645)\tPrec 68.359% (69.663%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.902 (4.902)\tLoss 1.1114 (1.1114)\tPrec 60.547% (60.547%)\n",
      " * Prec 59.680% \n",
      "best acc: 65.800000\n",
      "Epoch: [22][0/196]\tTime 5.680 (5.680)\tData 5.659 (5.659)\tLoss 0.9069 (0.9069)\tPrec 69.141% (69.141%)\n",
      "Epoch: [22][100/196]\tTime 0.039 (0.083)\tData 0.001 (0.057)\tLoss 0.7768 (0.8481)\tPrec 69.922% (70.355%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.933 (4.933)\tLoss 0.9117 (0.9117)\tPrec 68.359% (68.359%)\n",
      " * Prec 68.460% \n",
      "best acc: 68.460000\n",
      "Epoch: [23][0/196]\tTime 5.629 (5.629)\tData 5.605 (5.605)\tLoss 0.7836 (0.7836)\tPrec 71.875% (71.875%)\n",
      "Epoch: [23][100/196]\tTime 0.026 (0.083)\tData 0.001 (0.056)\tLoss 0.9181 (0.8388)\tPrec 67.969% (70.479%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.821 (4.821)\tLoss 0.9175 (0.9175)\tPrec 71.094% (71.094%)\n",
      " * Prec 67.250% \n",
      "best acc: 68.460000\n",
      "Epoch: [24][0/196]\tTime 5.687 (5.687)\tData 5.665 (5.665)\tLoss 0.8483 (0.8483)\tPrec 71.094% (71.094%)\n",
      "Epoch: [24][100/196]\tTime 0.027 (0.085)\tData 0.001 (0.057)\tLoss 0.8124 (0.8305)\tPrec 73.438% (70.838%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.863 (4.863)\tLoss 1.4474 (1.4474)\tPrec 58.594% (58.594%)\n",
      " * Prec 56.050% \n",
      "best acc: 68.460000\n",
      "Epoch: [25][0/196]\tTime 5.586 (5.586)\tData 5.564 (5.564)\tLoss 1.0642 (1.0642)\tPrec 61.328% (61.328%)\n",
      "Epoch: [25][100/196]\tTime 0.026 (0.084)\tData 0.001 (0.056)\tLoss 0.8274 (0.8519)\tPrec 68.750% (70.119%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.433 (4.433)\tLoss 0.9377 (0.9377)\tPrec 66.016% (66.016%)\n",
      " * Prec 67.020% \n",
      "best acc: 68.460000\n",
      "Epoch: [26][0/196]\tTime 4.364 (4.364)\tData 4.341 (4.341)\tLoss 0.7200 (0.7200)\tPrec 73.828% (73.828%)\n",
      "Epoch: [26][100/196]\tTime 0.019 (0.063)\tData 0.001 (0.044)\tLoss 0.7989 (0.8177)\tPrec 72.266% (71.272%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.093 (4.093)\tLoss 0.9436 (0.9436)\tPrec 68.750% (68.750%)\n",
      " * Prec 68.200% \n",
      "best acc: 68.460000\n",
      "Epoch: [27][0/196]\tTime 5.714 (5.714)\tData 5.685 (5.685)\tLoss 0.9267 (0.9267)\tPrec 66.406% (66.406%)\n",
      "Epoch: [27][100/196]\tTime 0.028 (0.087)\tData 0.001 (0.057)\tLoss 0.8300 (0.8224)\tPrec 69.922% (71.399%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.496 (4.496)\tLoss 0.9973 (0.9973)\tPrec 64.844% (64.844%)\n",
      " * Prec 65.330% \n",
      "best acc: 68.460000\n",
      "Epoch: [28][0/196]\tTime 5.781 (5.781)\tData 5.756 (5.756)\tLoss 0.7758 (0.7758)\tPrec 71.094% (71.094%)\n",
      "Epoch: [28][100/196]\tTime 0.032 (0.091)\tData 0.001 (0.058)\tLoss 0.8080 (0.8045)\tPrec 74.609% (71.863%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.771 (4.771)\tLoss 1.3302 (1.3302)\tPrec 60.938% (60.938%)\n",
      " * Prec 56.270% \n",
      "best acc: 68.460000\n",
      "Epoch: [29][0/196]\tTime 5.945 (5.945)\tData 5.920 (5.920)\tLoss 0.8106 (0.8106)\tPrec 74.219% (74.219%)\n",
      "Epoch: [29][100/196]\tTime 0.023 (0.092)\tData 0.001 (0.059)\tLoss 0.8248 (0.8155)\tPrec 71.875% (71.496%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.892 (4.892)\tLoss 1.0441 (1.0441)\tPrec 61.328% (61.328%)\n",
      " * Prec 63.600% \n",
      "best acc: 68.460000\n",
      "Epoch: [30][0/196]\tTime 5.791 (5.791)\tData 5.764 (5.764)\tLoss 0.8762 (0.8762)\tPrec 71.484% (71.484%)\n",
      "Epoch: [30][100/196]\tTime 0.022 (0.089)\tData 0.001 (0.058)\tLoss 0.9649 (0.8180)\tPrec 67.188% (71.202%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 5.032 (5.032)\tLoss 0.8621 (0.8621)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.590% \n",
      "best acc: 69.590000\n",
      "Epoch: [31][0/196]\tTime 6.036 (6.036)\tData 6.010 (6.010)\tLoss 0.6887 (0.6887)\tPrec 75.391% (75.391%)\n",
      "Epoch: [31][100/196]\tTime 0.025 (0.088)\tData 0.001 (0.060)\tLoss 0.8978 (0.8147)\tPrec 66.797% (71.376%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.288 (4.288)\tLoss 0.9070 (0.9070)\tPrec 66.016% (66.016%)\n",
      " * Prec 68.000% \n",
      "best acc: 69.590000\n",
      "Epoch: [32][0/196]\tTime 4.402 (4.402)\tData 4.375 (4.375)\tLoss 0.8316 (0.8316)\tPrec 71.094% (71.094%)\n",
      "Epoch: [32][100/196]\tTime 0.019 (0.070)\tData 0.001 (0.044)\tLoss 0.7848 (0.7955)\tPrec 72.266% (72.312%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.743 (3.743)\tLoss 1.0644 (1.0644)\tPrec 62.500% (62.500%)\n",
      " * Prec 61.730% \n",
      "best acc: 69.590000\n",
      "Epoch: [33][0/196]\tTime 5.283 (5.283)\tData 5.259 (5.259)\tLoss 0.8803 (0.8803)\tPrec 66.406% (66.406%)\n",
      "Epoch: [33][100/196]\tTime 0.019 (0.084)\tData 0.001 (0.053)\tLoss 0.8302 (0.7987)\tPrec 69.531% (72.173%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.840 (3.840)\tLoss 0.9772 (0.9772)\tPrec 64.062% (64.062%)\n",
      " * Prec 66.420% \n",
      "best acc: 69.590000\n",
      "Epoch: [34][0/196]\tTime 4.425 (4.425)\tData 4.396 (4.396)\tLoss 0.7411 (0.7411)\tPrec 74.219% (74.219%)\n",
      "Epoch: [34][100/196]\tTime 0.020 (0.071)\tData 0.001 (0.044)\tLoss 0.7548 (0.7776)\tPrec 75.000% (73.012%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.891 (3.891)\tLoss 0.8319 (0.8319)\tPrec 70.703% (70.703%)\n",
      " * Prec 69.170% \n",
      "best acc: 69.590000\n",
      "Epoch: [35][0/196]\tTime 4.353 (4.353)\tData 4.326 (4.326)\tLoss 0.7478 (0.7478)\tPrec 76.953% (76.953%)\n",
      "Epoch: [35][100/196]\tTime 0.055 (0.067)\tData 0.000 (0.043)\tLoss 0.7663 (0.7777)\tPrec 72.656% (72.989%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.867 (3.867)\tLoss 0.8532 (0.8532)\tPrec 69.531% (69.531%)\n",
      " * Prec 69.530% \n",
      "best acc: 69.590000\n",
      "Epoch: [36][0/196]\tTime 4.435 (4.435)\tData 4.413 (4.413)\tLoss 0.7635 (0.7635)\tPrec 74.219% (74.219%)\n",
      "Epoch: [36][100/196]\tTime 0.052 (0.099)\tData 0.001 (0.044)\tLoss 0.7666 (0.7827)\tPrec 72.656% (72.699%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.862 (3.862)\tLoss 0.8212 (0.8212)\tPrec 69.141% (69.141%)\n",
      " * Prec 71.190% \n",
      "best acc: 71.190000\n",
      "Epoch: [37][0/196]\tTime 4.608 (4.608)\tData 4.575 (4.575)\tLoss 0.8625 (0.8625)\tPrec 66.406% (66.406%)\n",
      "Epoch: [37][100/196]\tTime 0.037 (0.080)\tData 0.001 (0.046)\tLoss 0.6683 (0.7872)\tPrec 77.344% (72.745%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.696 (4.696)\tLoss 1.3722 (1.3722)\tPrec 58.594% (58.594%)\n",
      " * Prec 59.490% \n",
      "best acc: 71.190000\n",
      "Epoch: [38][0/196]\tTime 5.709 (5.709)\tData 5.689 (5.689)\tLoss 0.8356 (0.8356)\tPrec 69.141% (69.141%)\n",
      "Epoch: [38][100/196]\tTime 0.039 (0.084)\tData 0.001 (0.057)\tLoss 0.8669 (0.7758)\tPrec 67.188% (72.765%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.806 (3.806)\tLoss 1.3810 (1.3810)\tPrec 59.375% (59.375%)\n",
      " * Prec 56.500% \n",
      "best acc: 71.190000\n",
      "Epoch: [39][0/196]\tTime 4.308 (4.308)\tData 4.287 (4.287)\tLoss 0.7095 (0.7095)\tPrec 77.344% (77.344%)\n",
      "Epoch: [39][100/196]\tTime 0.038 (0.068)\tData 0.001 (0.043)\tLoss 0.6998 (0.7843)\tPrec 73.828% (72.757%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.734 (3.734)\tLoss 0.8832 (0.8832)\tPrec 67.578% (67.578%)\n",
      " * Prec 69.070% \n",
      "best acc: 71.190000\n",
      "Epoch: [40][0/196]\tTime 4.295 (4.295)\tData 4.273 (4.273)\tLoss 0.8133 (0.8133)\tPrec 68.750% (68.750%)\n",
      "Epoch: [40][100/196]\tTime 0.020 (0.065)\tData 0.001 (0.043)\tLoss 0.7838 (0.7725)\tPrec 73.438% (73.016%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.678 (3.678)\tLoss 0.9757 (0.9757)\tPrec 69.141% (69.141%)\n",
      " * Prec 67.880% \n",
      "best acc: 71.190000\n",
      "Epoch: [41][0/196]\tTime 4.310 (4.310)\tData 4.290 (4.290)\tLoss 0.8936 (0.8936)\tPrec 72.266% (72.266%)\n",
      "Epoch: [41][100/196]\tTime 0.019 (0.067)\tData 0.001 (0.043)\tLoss 0.7050 (0.7552)\tPrec 74.609% (73.650%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.706 (3.706)\tLoss 0.8062 (0.8062)\tPrec 70.312% (70.312%)\n",
      " * Prec 70.010% \n",
      "best acc: 71.190000\n",
      "Epoch: [42][0/196]\tTime 4.282 (4.282)\tData 4.252 (4.252)\tLoss 0.7733 (0.7733)\tPrec 71.875% (71.875%)\n",
      "Epoch: [42][100/196]\tTime 0.020 (0.062)\tData 0.001 (0.043)\tLoss 0.7613 (0.7635)\tPrec 76.172% (73.395%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.735 (3.735)\tLoss 0.9347 (0.9347)\tPrec 63.672% (63.672%)\n",
      " * Prec 66.000% \n",
      "best acc: 71.190000\n",
      "Epoch: [43][0/196]\tTime 4.312 (4.312)\tData 4.280 (4.280)\tLoss 0.6607 (0.6607)\tPrec 76.562% (76.562%)\n",
      "Epoch: [43][100/196]\tTime 0.036 (0.079)\tData 0.001 (0.043)\tLoss 0.8358 (0.7634)\tPrec 69.531% (73.449%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.890 (3.890)\tLoss 0.8506 (0.8506)\tPrec 69.141% (69.141%)\n",
      " * Prec 69.480% \n",
      "best acc: 71.190000\n",
      "Epoch: [44][0/196]\tTime 4.638 (4.638)\tData 4.613 (4.613)\tLoss 0.6566 (0.6566)\tPrec 78.906% (78.906%)\n",
      "Epoch: [44][100/196]\tTime 0.020 (0.082)\tData 0.001 (0.046)\tLoss 0.7510 (0.7647)\tPrec 72.656% (73.190%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.797 (3.797)\tLoss 0.8747 (0.8747)\tPrec 69.922% (69.922%)\n",
      " * Prec 68.190% \n",
      "best acc: 71.190000\n",
      "Epoch: [45][0/196]\tTime 4.587 (4.587)\tData 4.561 (4.561)\tLoss 0.7650 (0.7650)\tPrec 75.391% (75.391%)\n",
      "Epoch: [45][100/196]\tTime 0.020 (0.081)\tData 0.001 (0.046)\tLoss 0.8532 (0.7460)\tPrec 71.484% (74.149%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.952 (3.952)\tLoss 1.0221 (1.0221)\tPrec 67.578% (67.578%)\n",
      " * Prec 67.810% \n",
      "best acc: 71.190000\n",
      "Epoch: [46][0/196]\tTime 4.274 (4.274)\tData 4.249 (4.249)\tLoss 0.6637 (0.6637)\tPrec 76.562% (76.562%)\n",
      "Epoch: [46][100/196]\tTime 0.020 (0.075)\tData 0.001 (0.043)\tLoss 0.6457 (0.7580)\tPrec 79.297% (73.662%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.650 (3.650)\tLoss 1.0415 (1.0415)\tPrec 61.719% (61.719%)\n",
      " * Prec 61.310% \n",
      "best acc: 71.190000\n",
      "Epoch: [47][0/196]\tTime 4.200 (4.200)\tData 4.174 (4.174)\tLoss 0.6324 (0.6324)\tPrec 77.734% (77.734%)\n",
      "Epoch: [47][100/196]\tTime 0.019 (0.075)\tData 0.001 (0.042)\tLoss 0.6967 (0.7534)\tPrec 75.000% (73.577%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.687 (3.687)\tLoss 1.4335 (1.4335)\tPrec 54.688% (54.688%)\n",
      " * Prec 53.710% \n",
      "best acc: 71.190000\n",
      "Epoch: [48][0/196]\tTime 4.340 (4.340)\tData 4.314 (4.314)\tLoss 0.8149 (0.8149)\tPrec 68.750% (68.750%)\n",
      "Epoch: [48][100/196]\tTime 0.021 (0.078)\tData 0.001 (0.043)\tLoss 0.7446 (0.7591)\tPrec 74.219% (73.623%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.639 (3.639)\tLoss 1.3255 (1.3255)\tPrec 57.812% (57.812%)\n",
      " * Prec 59.330% \n",
      "best acc: 71.190000\n",
      "Epoch: [49][0/196]\tTime 4.335 (4.335)\tData 4.312 (4.312)\tLoss 0.7474 (0.7474)\tPrec 71.875% (71.875%)\n",
      "Epoch: [49][100/196]\tTime 0.020 (0.078)\tData 0.001 (0.043)\tLoss 0.7419 (0.7515)\tPrec 74.609% (74.002%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.723 (3.723)\tLoss 1.4863 (1.4863)\tPrec 52.344% (52.344%)\n",
      " * Prec 51.820% \n",
      "best acc: 71.190000\n",
      "Epoch: [50][0/196]\tTime 4.513 (4.513)\tData 4.484 (4.484)\tLoss 0.7426 (0.7426)\tPrec 73.828% (73.828%)\n",
      "Epoch: [50][100/196]\tTime 0.020 (0.079)\tData 0.001 (0.045)\tLoss 0.8152 (0.7469)\tPrec 69.141% (73.917%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.672 (3.672)\tLoss 0.8352 (0.8352)\tPrec 69.531% (69.531%)\n",
      " * Prec 71.490% \n",
      "best acc: 71.490000\n",
      "Epoch: [51][0/196]\tTime 4.344 (4.344)\tData 4.319 (4.319)\tLoss 0.7337 (0.7337)\tPrec 71.094% (71.094%)\n",
      "Epoch: [51][100/196]\tTime 0.054 (0.093)\tData 0.001 (0.043)\tLoss 0.7471 (0.7347)\tPrec 73.047% (74.180%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.737 (3.737)\tLoss 1.0440 (1.0440)\tPrec 65.234% (65.234%)\n",
      " * Prec 64.190% \n",
      "best acc: 71.490000\n",
      "Epoch: [52][0/196]\tTime 4.818 (4.818)\tData 4.777 (4.777)\tLoss 0.6823 (0.6823)\tPrec 74.609% (74.609%)\n",
      "Epoch: [52][100/196]\tTime 0.076 (0.123)\tData 0.001 (0.048)\tLoss 0.7241 (0.7453)\tPrec 75.000% (73.963%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.898 (3.898)\tLoss 1.5050 (1.5050)\tPrec 61.719% (61.719%)\n",
      " * Prec 58.280% \n",
      "best acc: 71.490000\n",
      "Epoch: [53][0/196]\tTime 4.707 (4.707)\tData 4.670 (4.670)\tLoss 0.6725 (0.6725)\tPrec 74.219% (74.219%)\n",
      "Epoch: [53][100/196]\tTime 0.055 (0.106)\tData 0.001 (0.047)\tLoss 0.7531 (0.7385)\tPrec 73.828% (74.138%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.858 (3.858)\tLoss 1.1454 (1.1454)\tPrec 62.500% (62.500%)\n",
      " * Prec 66.740% \n",
      "best acc: 71.490000\n",
      "Epoch: [54][0/196]\tTime 4.455 (4.455)\tData 4.428 (4.428)\tLoss 0.7417 (0.7417)\tPrec 75.781% (75.781%)\n",
      "Epoch: [54][100/196]\tTime 0.055 (0.097)\tData 0.001 (0.044)\tLoss 0.7704 (0.7520)\tPrec 70.703% (73.944%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.932 (3.932)\tLoss 1.2701 (1.2701)\tPrec 63.672% (63.672%)\n",
      " * Prec 63.040% \n",
      "best acc: 71.490000\n",
      "Epoch: [55][0/196]\tTime 5.029 (5.029)\tData 4.999 (4.999)\tLoss 0.8158 (0.8158)\tPrec 74.219% (74.219%)\n",
      "Epoch: [55][100/196]\tTime 0.077 (0.092)\tData 0.001 (0.050)\tLoss 0.7444 (0.7417)\tPrec 77.344% (74.091%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.947 (4.947)\tLoss 1.2017 (1.2017)\tPrec 61.719% (61.719%)\n",
      " * Prec 61.070% \n",
      "best acc: 71.490000\n",
      "Epoch: [56][0/196]\tTime 5.778 (5.778)\tData 5.743 (5.743)\tLoss 0.7143 (0.7143)\tPrec 77.734% (77.734%)\n",
      "Epoch: [56][100/196]\tTime 0.078 (0.125)\tData 0.001 (0.058)\tLoss 0.6618 (0.7377)\tPrec 75.781% (74.470%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.825 (4.825)\tLoss 1.1262 (1.1262)\tPrec 63.281% (63.281%)\n",
      " * Prec 64.030% \n",
      "best acc: 71.490000\n",
      "Epoch: [57][0/196]\tTime 5.771 (5.771)\tData 5.737 (5.737)\tLoss 0.6810 (0.6810)\tPrec 75.000% (75.000%)\n",
      "Epoch: [57][100/196]\tTime 0.039 (0.093)\tData 0.001 (0.058)\tLoss 0.7618 (0.7383)\tPrec 73.438% (74.192%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.874 (4.874)\tLoss 1.1272 (1.1272)\tPrec 63.672% (63.672%)\n",
      " * Prec 65.940% \n",
      "best acc: 71.490000\n",
      "Epoch: [58][0/196]\tTime 5.740 (5.740)\tData 5.717 (5.717)\tLoss 0.7854 (0.7854)\tPrec 69.922% (69.922%)\n",
      "Epoch: [58][100/196]\tTime 0.056 (0.095)\tData 0.001 (0.057)\tLoss 0.6012 (0.7310)\tPrec 80.469% (74.722%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.653 (4.653)\tLoss 1.0043 (1.0043)\tPrec 67.578% (67.578%)\n",
      " * Prec 66.200% \n",
      "best acc: 71.490000\n",
      "Epoch: [59][0/196]\tTime 5.730 (5.730)\tData 5.705 (5.705)\tLoss 0.6666 (0.6666)\tPrec 79.297% (79.297%)\n",
      "Epoch: [59][100/196]\tTime 0.027 (0.083)\tData 0.001 (0.057)\tLoss 0.6006 (0.7363)\tPrec 80.469% (74.288%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.571 (4.571)\tLoss 1.0218 (1.0218)\tPrec 62.891% (62.891%)\n",
      " * Prec 64.930% \n",
      "best acc: 71.490000\n",
      "Epoch: [60][0/196]\tTime 5.692 (5.692)\tData 5.659 (5.659)\tLoss 0.6803 (0.6803)\tPrec 75.781% (75.781%)\n",
      "Epoch: [60][100/196]\tTime 0.029 (0.086)\tData 0.001 (0.057)\tLoss 0.7926 (0.7423)\tPrec 73.047% (74.002%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.766 (4.766)\tLoss 0.8468 (0.8468)\tPrec 69.531% (69.531%)\n",
      " * Prec 68.410% \n",
      "best acc: 71.490000\n",
      "Epoch: [61][0/196]\tTime 5.797 (5.797)\tData 5.768 (5.768)\tLoss 0.6575 (0.6575)\tPrec 73.828% (73.828%)\n",
      "Epoch: [61][100/196]\tTime 0.026 (0.088)\tData 0.001 (0.058)\tLoss 0.7104 (0.7244)\tPrec 70.703% (74.683%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.879 (4.879)\tLoss 1.0723 (1.0723)\tPrec 68.359% (68.359%)\n",
      " * Prec 64.610% \n",
      "best acc: 71.490000\n",
      "Epoch: [62][0/196]\tTime 5.663 (5.663)\tData 5.627 (5.627)\tLoss 0.8218 (0.8218)\tPrec 71.875% (71.875%)\n",
      "Epoch: [62][100/196]\tTime 0.030 (0.105)\tData 0.001 (0.056)\tLoss 0.7802 (0.7328)\tPrec 74.609% (74.586%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.825 (4.825)\tLoss 1.0253 (1.0253)\tPrec 62.891% (62.891%)\n",
      " * Prec 65.220% \n",
      "best acc: 71.490000\n",
      "Epoch: [63][0/196]\tTime 5.667 (5.667)\tData 5.624 (5.624)\tLoss 0.7242 (0.7242)\tPrec 70.312% (70.312%)\n",
      "Epoch: [63][100/196]\tTime 0.033 (0.109)\tData 0.001 (0.056)\tLoss 0.7887 (0.7250)\tPrec 71.094% (74.582%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.751 (4.751)\tLoss 0.8823 (0.8823)\tPrec 67.578% (67.578%)\n",
      " * Prec 70.670% \n",
      "best acc: 71.490000\n",
      "Epoch: [64][0/196]\tTime 5.729 (5.729)\tData 5.694 (5.694)\tLoss 0.7906 (0.7906)\tPrec 70.312% (70.312%)\n",
      "Epoch: [64][100/196]\tTime 0.045 (0.126)\tData 0.001 (0.057)\tLoss 0.6847 (0.7330)\tPrec 76.562% (74.563%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.684 (4.684)\tLoss 1.3651 (1.3651)\tPrec 57.031% (57.031%)\n",
      " * Prec 60.870% \n",
      "best acc: 71.490000\n",
      "Epoch: [65][0/196]\tTime 5.638 (5.638)\tData 5.588 (5.588)\tLoss 0.6829 (0.6829)\tPrec 76.172% (76.172%)\n",
      "Epoch: [65][100/196]\tTime 0.039 (0.129)\tData 0.001 (0.056)\tLoss 0.7413 (0.7249)\tPrec 75.000% (75.012%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.747 (4.747)\tLoss 1.1213 (1.1213)\tPrec 62.109% (62.109%)\n",
      " * Prec 63.820% \n",
      "best acc: 71.490000\n",
      "Epoch: [66][0/196]\tTime 5.748 (5.748)\tData 5.708 (5.708)\tLoss 0.6887 (0.6887)\tPrec 72.266% (72.266%)\n",
      "Epoch: [66][100/196]\tTime 0.034 (0.117)\tData 0.001 (0.057)\tLoss 0.6242 (0.7359)\tPrec 77.734% (74.451%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.831 (4.831)\tLoss 0.9504 (0.9504)\tPrec 66.797% (66.797%)\n",
      " * Prec 67.960% \n",
      "best acc: 71.490000\n",
      "Epoch: [67][0/196]\tTime 5.695 (5.695)\tData 5.657 (5.657)\tLoss 0.6536 (0.6536)\tPrec 78.516% (78.516%)\n",
      "Epoch: [67][100/196]\tTime 0.031 (0.098)\tData 0.001 (0.057)\tLoss 0.6504 (0.7200)\tPrec 74.609% (75.364%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.792 (4.792)\tLoss 0.8908 (0.8908)\tPrec 69.141% (69.141%)\n",
      " * Prec 69.270% \n",
      "best acc: 71.490000\n",
      "Epoch: [68][0/196]\tTime 5.826 (5.826)\tData 5.801 (5.801)\tLoss 0.7904 (0.7904)\tPrec 74.219% (74.219%)\n",
      "Epoch: [68][100/196]\tTime 0.052 (0.100)\tData 0.001 (0.058)\tLoss 0.7643 (0.7113)\tPrec 74.609% (74.985%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.817 (4.817)\tLoss 0.8627 (0.8627)\tPrec 70.703% (70.703%)\n",
      " * Prec 69.720% \n",
      "best acc: 71.490000\n",
      "Epoch: [69][0/196]\tTime 5.680 (5.680)\tData 5.652 (5.652)\tLoss 0.7338 (0.7338)\tPrec 73.438% (73.438%)\n",
      "Epoch: [69][100/196]\tTime 0.052 (0.095)\tData 0.001 (0.057)\tLoss 0.7716 (0.7150)\tPrec 71.484% (74.876%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.700 (4.700)\tLoss 1.0764 (1.0764)\tPrec 68.359% (68.359%)\n",
      " * Prec 68.960% \n",
      "best acc: 71.490000\n",
      "Epoch: [70][0/196]\tTime 5.746 (5.746)\tData 5.720 (5.720)\tLoss 0.6901 (0.6901)\tPrec 75.391% (75.391%)\n",
      "Epoch: [70][100/196]\tTime 0.028 (0.088)\tData 0.001 (0.057)\tLoss 0.7615 (0.7269)\tPrec 72.656% (74.725%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.738 (4.738)\tLoss 0.8900 (0.8900)\tPrec 69.141% (69.141%)\n",
      " * Prec 71.060% \n",
      "best acc: 71.490000\n",
      "Epoch: [71][0/196]\tTime 5.679 (5.679)\tData 5.659 (5.659)\tLoss 0.6859 (0.6859)\tPrec 75.000% (75.000%)\n",
      "Epoch: [71][100/196]\tTime 0.023 (0.082)\tData 0.001 (0.057)\tLoss 0.6375 (0.7285)\tPrec 78.516% (74.428%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.857 (4.857)\tLoss 0.8024 (0.8024)\tPrec 71.094% (71.094%)\n",
      " * Prec 71.700% \n",
      "best acc: 71.700000\n",
      "Epoch: [72][0/196]\tTime 5.632 (5.632)\tData 5.610 (5.610)\tLoss 0.7275 (0.7275)\tPrec 72.656% (72.656%)\n",
      "Epoch: [72][100/196]\tTime 0.045 (0.098)\tData 0.001 (0.056)\tLoss 0.7244 (0.7116)\tPrec 73.438% (75.182%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.887 (4.887)\tLoss 0.7473 (0.7473)\tPrec 72.266% (72.266%)\n",
      " * Prec 72.700% \n",
      "best acc: 72.700000\n",
      "Epoch: [73][0/196]\tTime 5.510 (5.510)\tData 5.471 (5.471)\tLoss 0.5983 (0.5983)\tPrec 78.516% (78.516%)\n",
      "Epoch: [73][100/196]\tTime 0.036 (0.107)\tData 0.001 (0.055)\tLoss 0.7139 (0.7167)\tPrec 71.484% (75.019%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.796 (4.796)\tLoss 0.8577 (0.8577)\tPrec 69.531% (69.531%)\n",
      " * Prec 72.250% \n",
      "best acc: 72.700000\n",
      "Epoch: [74][0/196]\tTime 5.712 (5.712)\tData 5.685 (5.685)\tLoss 0.6421 (0.6421)\tPrec 78.125% (78.125%)\n",
      "Epoch: [74][100/196]\tTime 0.027 (0.082)\tData 0.001 (0.057)\tLoss 0.7936 (0.7021)\tPrec 72.266% (75.298%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.952 (4.952)\tLoss 0.8978 (0.8978)\tPrec 67.578% (67.578%)\n",
      " * Prec 69.900% \n",
      "best acc: 72.700000\n",
      "Epoch: [75][0/196]\tTime 5.676 (5.676)\tData 5.651 (5.651)\tLoss 0.6893 (0.6893)\tPrec 75.000% (75.000%)\n",
      "Epoch: [75][100/196]\tTime 0.026 (0.082)\tData 0.001 (0.057)\tLoss 0.6866 (0.7079)\tPrec 76.953% (75.317%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.799 (4.799)\tLoss 0.9410 (0.9410)\tPrec 67.188% (67.188%)\n",
      " * Prec 67.830% \n",
      "best acc: 72.700000\n",
      "Epoch: [76][0/196]\tTime 5.626 (5.626)\tData 5.600 (5.600)\tLoss 0.6618 (0.6618)\tPrec 78.516% (78.516%)\n",
      "Epoch: [76][100/196]\tTime 0.030 (0.083)\tData 0.001 (0.056)\tLoss 0.7533 (0.7099)\tPrec 73.047% (75.371%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.781 (4.781)\tLoss 0.9749 (0.9749)\tPrec 67.188% (67.188%)\n",
      " * Prec 69.320% \n",
      "best acc: 72.700000\n",
      "Epoch: [77][0/196]\tTime 5.479 (5.479)\tData 5.437 (5.437)\tLoss 0.5792 (0.5792)\tPrec 79.297% (79.297%)\n",
      "Epoch: [77][100/196]\tTime 0.025 (0.086)\tData 0.001 (0.055)\tLoss 0.6128 (0.7043)\tPrec 75.391% (75.634%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.705 (4.705)\tLoss 0.7866 (0.7866)\tPrec 74.219% (74.219%)\n",
      " * Prec 73.100% \n",
      "best acc: 73.100000\n",
      "Epoch: [78][0/196]\tTime 5.571 (5.571)\tData 5.529 (5.529)\tLoss 0.6407 (0.6407)\tPrec 77.344% (77.344%)\n",
      "Epoch: [78][100/196]\tTime 0.034 (0.110)\tData 0.001 (0.055)\tLoss 0.7961 (0.7025)\tPrec 75.000% (75.638%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.624 (4.624)\tLoss 0.8994 (0.8994)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.930% \n",
      "best acc: 73.100000\n",
      "Epoch: [79][0/196]\tTime 5.575 (5.575)\tData 5.521 (5.521)\tLoss 0.7595 (0.7595)\tPrec 73.438% (73.438%)\n",
      "Epoch: [79][100/196]\tTime 0.058 (0.116)\tData 0.001 (0.055)\tLoss 0.6804 (0.6972)\tPrec 76.562% (75.716%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.781 (4.781)\tLoss 1.2124 (1.2124)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.680% \n",
      "best acc: 73.100000\n",
      "Epoch: [80][0/196]\tTime 5.987 (5.987)\tData 5.953 (5.953)\tLoss 0.7136 (0.7136)\tPrec 75.781% (75.781%)\n",
      "Epoch: [80][100/196]\tTime 0.035 (0.110)\tData 0.001 (0.060)\tLoss 0.6141 (0.6469)\tPrec 79.297% (77.514%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.797 (4.797)\tLoss 0.6635 (0.6635)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.380% \n",
      "best acc: 76.380000\n",
      "Epoch: [81][0/196]\tTime 5.911 (5.911)\tData 5.870 (5.870)\tLoss 0.6596 (0.6596)\tPrec 76.562% (76.562%)\n",
      "Epoch: [81][100/196]\tTime 0.040 (0.100)\tData 0.001 (0.059)\tLoss 0.5115 (0.6303)\tPrec 81.641% (78.307%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.776 (4.776)\tLoss 0.6503 (0.6503)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.110% \n",
      "best acc: 76.380000\n",
      "Epoch: [82][0/196]\tTime 5.697 (5.697)\tData 5.671 (5.671)\tLoss 0.6300 (0.6300)\tPrec 75.781% (75.781%)\n",
      "Epoch: [82][100/196]\tTime 0.078 (0.120)\tData 0.001 (0.057)\tLoss 0.6270 (0.6363)\tPrec 78.125% (77.700%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.875 (4.875)\tLoss 0.7082 (0.7082)\tPrec 77.734% (77.734%)\n",
      " * Prec 75.160% \n",
      "best acc: 76.380000\n",
      "Epoch: [83][0/196]\tTime 5.634 (5.634)\tData 5.594 (5.594)\tLoss 0.6315 (0.6315)\tPrec 78.125% (78.125%)\n",
      "Epoch: [83][100/196]\tTime 0.056 (0.122)\tData 0.001 (0.056)\tLoss 0.6721 (0.6321)\tPrec 75.000% (77.986%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.706 (4.706)\tLoss 0.6476 (0.6476)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.430% \n",
      "best acc: 76.430000\n",
      "Epoch: [84][0/196]\tTime 5.603 (5.603)\tData 5.578 (5.578)\tLoss 0.6197 (0.6197)\tPrec 76.953% (76.953%)\n",
      "Epoch: [84][100/196]\tTime 0.053 (0.107)\tData 0.001 (0.056)\tLoss 0.5321 (0.6178)\tPrec 81.250% (78.268%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.863 (4.863)\tLoss 0.6414 (0.6414)\tPrec 76.953% (76.953%)\n",
      " * Prec 76.930% \n",
      "best acc: 76.930000\n",
      "Epoch: [85][0/196]\tTime 5.714 (5.714)\tData 5.689 (5.689)\tLoss 0.7170 (0.7170)\tPrec 79.297% (79.297%)\n",
      "Epoch: [85][100/196]\tTime 0.094 (0.105)\tData 0.001 (0.057)\tLoss 0.6361 (0.6273)\tPrec 80.078% (78.287%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.692 (4.692)\tLoss 0.6645 (0.6645)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.740% \n",
      "best acc: 76.930000\n",
      "Epoch: [86][0/196]\tTime 5.779 (5.779)\tData 5.751 (5.751)\tLoss 0.6161 (0.6161)\tPrec 80.469% (80.469%)\n",
      "Epoch: [86][100/196]\tTime 0.071 (0.113)\tData 0.001 (0.058)\tLoss 0.6528 (0.6212)\tPrec 79.688% (78.458%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.849 (4.849)\tLoss 0.6428 (0.6428)\tPrec 75.391% (75.391%)\n",
      " * Prec 75.640% \n",
      "best acc: 76.930000\n",
      "Epoch: [87][0/196]\tTime 5.662 (5.662)\tData 5.629 (5.629)\tLoss 0.6522 (0.6522)\tPrec 81.641% (81.641%)\n",
      "Epoch: [87][100/196]\tTime 0.038 (0.114)\tData 0.001 (0.056)\tLoss 0.6522 (0.6241)\tPrec 77.344% (78.701%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.840 (4.840)\tLoss 0.6571 (0.6571)\tPrec 79.297% (79.297%)\n",
      " * Prec 76.260% \n",
      "best acc: 76.930000\n",
      "Epoch: [88][0/196]\tTime 5.668 (5.668)\tData 5.647 (5.647)\tLoss 0.6365 (0.6365)\tPrec 77.344% (77.344%)\n",
      "Epoch: [88][100/196]\tTime 0.038 (0.088)\tData 0.001 (0.057)\tLoss 0.6132 (0.6184)\tPrec 76.953% (78.342%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.955 (4.955)\tLoss 0.7499 (0.7499)\tPrec 72.656% (72.656%)\n",
      " * Prec 73.750% \n",
      "best acc: 76.930000\n",
      "Epoch: [89][0/196]\tTime 5.518 (5.518)\tData 5.493 (5.493)\tLoss 0.6763 (0.6763)\tPrec 78.516% (78.516%)\n",
      "Epoch: [89][100/196]\tTime 0.042 (0.087)\tData 0.001 (0.055)\tLoss 0.5124 (0.6191)\tPrec 81.641% (78.628%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.660 (4.660)\tLoss 0.7255 (0.7255)\tPrec 75.781% (75.781%)\n",
      " * Prec 75.940% \n",
      "best acc: 76.930000\n",
      "Epoch: [90][0/196]\tTime 5.689 (5.689)\tData 5.663 (5.663)\tLoss 0.6029 (0.6029)\tPrec 79.688% (79.688%)\n",
      "Epoch: [90][100/196]\tTime 0.026 (0.085)\tData 0.001 (0.057)\tLoss 0.5269 (0.6112)\tPrec 82.422% (78.914%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.515 (4.515)\tLoss 0.6595 (0.6595)\tPrec 76.953% (76.953%)\n",
      " * Prec 76.820% \n",
      "best acc: 76.930000\n",
      "Epoch: [91][0/196]\tTime 5.769 (5.769)\tData 5.743 (5.743)\tLoss 0.5650 (0.5650)\tPrec 79.297% (79.297%)\n",
      "Epoch: [91][100/196]\tTime 0.028 (0.085)\tData 0.001 (0.058)\tLoss 0.8227 (0.6106)\tPrec 73.828% (79.042%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.840 (4.840)\tLoss 0.6602 (0.6602)\tPrec 76.172% (76.172%)\n",
      " * Prec 75.960% \n",
      "best acc: 76.930000\n",
      "Epoch: [92][0/196]\tTime 5.676 (5.676)\tData 5.647 (5.647)\tLoss 0.6997 (0.6997)\tPrec 77.734% (77.734%)\n",
      "Epoch: [92][100/196]\tTime 0.025 (0.085)\tData 0.001 (0.057)\tLoss 0.6093 (0.6156)\tPrec 79.688% (78.786%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.725 (4.725)\tLoss 0.6547 (0.6547)\tPrec 75.000% (75.000%)\n",
      " * Prec 75.680% \n",
      "best acc: 76.930000\n",
      "Epoch: [93][0/196]\tTime 5.515 (5.515)\tData 5.481 (5.481)\tLoss 0.5754 (0.5754)\tPrec 82.812% (82.812%)\n",
      "Epoch: [93][100/196]\tTime 0.041 (0.105)\tData 0.001 (0.055)\tLoss 0.5884 (0.6189)\tPrec 76.172% (78.543%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.738 (4.738)\tLoss 0.6527 (0.6527)\tPrec 78.906% (78.906%)\n",
      " * Prec 76.990% \n",
      "best acc: 76.990000\n",
      "Epoch: [94][0/196]\tTime 5.747 (5.747)\tData 5.715 (5.715)\tLoss 0.5933 (0.5933)\tPrec 78.125% (78.125%)\n",
      "Epoch: [94][100/196]\tTime 0.036 (0.105)\tData 0.001 (0.057)\tLoss 0.5946 (0.6293)\tPrec 78.125% (78.129%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.824 (4.824)\tLoss 0.6624 (0.6624)\tPrec 75.781% (75.781%)\n",
      " * Prec 75.890% \n",
      "best acc: 76.990000\n",
      "Epoch: [95][0/196]\tTime 5.691 (5.691)\tData 5.660 (5.660)\tLoss 0.6960 (0.6960)\tPrec 77.734% (77.734%)\n",
      "Epoch: [95][100/196]\tTime 0.040 (0.103)\tData 0.001 (0.057)\tLoss 0.6850 (0.6230)\tPrec 76.172% (78.268%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.631 (4.631)\tLoss 0.6956 (0.6956)\tPrec 77.734% (77.734%)\n",
      " * Prec 76.190% \n",
      "best acc: 76.990000\n",
      "Epoch: [96][0/196]\tTime 5.910 (5.910)\tData 5.882 (5.882)\tLoss 0.5713 (0.5713)\tPrec 78.125% (78.125%)\n",
      "Epoch: [96][100/196]\tTime 0.082 (0.117)\tData 0.001 (0.059)\tLoss 0.6091 (0.6157)\tPrec 81.250% (78.504%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.828 (4.828)\tLoss 0.6776 (0.6776)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.140% \n",
      "best acc: 76.990000\n",
      "Epoch: [97][0/196]\tTime 5.557 (5.557)\tData 5.513 (5.513)\tLoss 0.7023 (0.7023)\tPrec 79.297% (79.297%)\n",
      "Epoch: [97][100/196]\tTime 0.040 (0.130)\tData 0.001 (0.055)\tLoss 0.7506 (0.6112)\tPrec 75.000% (78.694%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.754 (4.754)\tLoss 0.6519 (0.6519)\tPrec 74.609% (74.609%)\n",
      " * Prec 76.930% \n",
      "best acc: 76.990000\n",
      "Epoch: [98][0/196]\tTime 5.752 (5.752)\tData 5.715 (5.715)\tLoss 0.6523 (0.6523)\tPrec 80.078% (80.078%)\n",
      "Epoch: [98][100/196]\tTime 0.057 (0.125)\tData 0.001 (0.057)\tLoss 0.6582 (0.6175)\tPrec 78.906% (78.388%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.671 (4.671)\tLoss 0.7254 (0.7254)\tPrec 76.562% (76.562%)\n",
      " * Prec 75.270% \n",
      "best acc: 76.990000\n",
      "Epoch: [99][0/196]\tTime 5.751 (5.751)\tData 5.723 (5.723)\tLoss 0.5382 (0.5382)\tPrec 81.641% (81.641%)\n",
      "Epoch: [99][100/196]\tTime 0.042 (0.109)\tData 0.001 (0.057)\tLoss 0.8166 (0.6143)\tPrec 73.047% (78.914%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.867 (4.867)\tLoss 0.6806 (0.6806)\tPrec 76.172% (76.172%)\n",
      " * Prec 76.450% \n",
      "best acc: 76.990000\n",
      "Epoch: [100][0/196]\tTime 5.739 (5.739)\tData 5.710 (5.710)\tLoss 0.6019 (0.6019)\tPrec 78.906% (78.906%)\n",
      "Epoch: [100][100/196]\tTime 0.039 (0.103)\tData 0.001 (0.057)\tLoss 0.6229 (0.6146)\tPrec 78.516% (78.581%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.703 (4.703)\tLoss 0.7199 (0.7199)\tPrec 77.344% (77.344%)\n",
      " * Prec 75.580% \n",
      "best acc: 76.990000\n",
      "Epoch: [101][0/196]\tTime 5.846 (5.846)\tData 5.821 (5.821)\tLoss 0.6194 (0.6194)\tPrec 77.734% (77.734%)\n",
      "Epoch: [101][100/196]\tTime 0.090 (0.102)\tData 0.001 (0.058)\tLoss 0.5867 (0.6085)\tPrec 78.906% (78.643%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.884 (4.884)\tLoss 0.7588 (0.7588)\tPrec 73.047% (73.047%)\n",
      " * Prec 73.200% \n",
      "best acc: 76.990000\n",
      "Epoch: [102][0/196]\tTime 5.536 (5.536)\tData 5.502 (5.502)\tLoss 0.6296 (0.6296)\tPrec 76.562% (76.562%)\n",
      "Epoch: [102][100/196]\tTime 0.088 (0.128)\tData 0.001 (0.055)\tLoss 0.6312 (0.6192)\tPrec 79.297% (78.732%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.731 (4.731)\tLoss 0.7335 (0.7335)\tPrec 74.219% (74.219%)\n",
      " * Prec 73.420% \n",
      "best acc: 76.990000\n",
      "Epoch: [103][0/196]\tTime 5.953 (5.953)\tData 5.919 (5.919)\tLoss 0.6808 (0.6808)\tPrec 76.562% (76.562%)\n",
      "Epoch: [103][100/196]\tTime 0.056 (0.097)\tData 0.001 (0.059)\tLoss 0.5668 (0.6132)\tPrec 82.422% (78.728%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.952 (4.952)\tLoss 0.7065 (0.7065)\tPrec 76.172% (76.172%)\n",
      " * Prec 75.550% \n",
      "best acc: 76.990000\n",
      "Epoch: [104][0/196]\tTime 5.580 (5.580)\tData 5.556 (5.556)\tLoss 0.6272 (0.6272)\tPrec 78.125% (78.125%)\n",
      "Epoch: [104][100/196]\tTime 0.059 (0.096)\tData 0.001 (0.056)\tLoss 0.5389 (0.6156)\tPrec 79.688% (78.724%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.649 (4.649)\tLoss 0.6973 (0.6973)\tPrec 76.172% (76.172%)\n",
      " * Prec 76.300% \n",
      "best acc: 76.990000\n",
      "Epoch: [105][0/196]\tTime 5.469 (5.469)\tData 5.435 (5.435)\tLoss 0.6068 (0.6068)\tPrec 78.125% (78.125%)\n",
      "Epoch: [105][100/196]\tTime 0.038 (0.084)\tData 0.001 (0.054)\tLoss 0.6770 (0.6155)\tPrec 77.344% (78.523%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.729 (4.729)\tLoss 0.6677 (0.6677)\tPrec 76.172% (76.172%)\n",
      " * Prec 77.850% \n",
      "best acc: 77.850000\n",
      "Epoch: [106][0/196]\tTime 5.637 (5.637)\tData 5.612 (5.612)\tLoss 0.6962 (0.6962)\tPrec 75.781% (75.781%)\n",
      "Epoch: [106][100/196]\tTime 0.035 (0.083)\tData 0.001 (0.056)\tLoss 0.6003 (0.6112)\tPrec 81.250% (78.806%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.831 (4.831)\tLoss 0.6065 (0.6065)\tPrec 80.078% (80.078%)\n",
      " * Prec 77.000% \n",
      "best acc: 77.850000\n",
      "Epoch: [107][0/196]\tTime 5.713 (5.713)\tData 5.688 (5.688)\tLoss 0.5659 (0.5659)\tPrec 79.297% (79.297%)\n",
      "Epoch: [107][100/196]\tTime 0.055 (0.088)\tData 0.001 (0.057)\tLoss 0.5831 (0.6156)\tPrec 79.688% (78.670%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.867 (4.867)\tLoss 0.8298 (0.8298)\tPrec 71.875% (71.875%)\n",
      " * Prec 72.370% \n",
      "best acc: 77.850000\n",
      "Epoch: [108][0/196]\tTime 5.675 (5.675)\tData 5.644 (5.644)\tLoss 0.5904 (0.5904)\tPrec 79.688% (79.688%)\n",
      "Epoch: [108][100/196]\tTime 0.054 (0.107)\tData 0.001 (0.057)\tLoss 0.5217 (0.6077)\tPrec 82.812% (78.933%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.753 (4.753)\tLoss 0.7504 (0.7504)\tPrec 75.781% (75.781%)\n",
      " * Prec 75.290% \n",
      "best acc: 77.850000\n",
      "Epoch: [109][0/196]\tTime 5.700 (5.700)\tData 5.667 (5.667)\tLoss 0.5722 (0.5722)\tPrec 81.641% (81.641%)\n",
      "Epoch: [109][100/196]\tTime 0.029 (0.085)\tData 0.001 (0.057)\tLoss 0.7144 (0.6097)\tPrec 75.781% (78.891%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.930 (4.930)\tLoss 0.6301 (0.6301)\tPrec 76.562% (76.562%)\n",
      " * Prec 77.370% \n",
      "best acc: 77.850000\n",
      "Epoch: [110][0/196]\tTime 5.721 (5.721)\tData 5.688 (5.688)\tLoss 0.5578 (0.5578)\tPrec 81.641% (81.641%)\n",
      "Epoch: [110][100/196]\tTime 0.024 (0.083)\tData 0.001 (0.057)\tLoss 0.4447 (0.6040)\tPrec 83.203% (79.053%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.968 (4.968)\tLoss 0.6761 (0.6761)\tPrec 74.219% (74.219%)\n",
      " * Prec 76.450% \n",
      "best acc: 77.850000\n",
      "Epoch: [111][0/196]\tTime 5.459 (5.459)\tData 5.437 (5.437)\tLoss 0.6362 (0.6362)\tPrec 78.906% (78.906%)\n",
      "Epoch: [111][100/196]\tTime 0.032 (0.080)\tData 0.001 (0.055)\tLoss 0.6079 (0.6113)\tPrec 80.078% (78.984%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.884 (4.884)\tLoss 0.6610 (0.6610)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.700% \n",
      "best acc: 77.850000\n",
      "Epoch: [112][0/196]\tTime 5.397 (5.397)\tData 5.348 (5.348)\tLoss 0.6044 (0.6044)\tPrec 78.516% (78.516%)\n",
      "Epoch: [112][100/196]\tTime 0.023 (0.117)\tData 0.001 (0.054)\tLoss 0.6460 (0.6077)\tPrec 77.344% (78.941%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.724 (4.724)\tLoss 0.6862 (0.6862)\tPrec 75.000% (75.000%)\n",
      " * Prec 76.650% \n",
      "best acc: 77.850000\n",
      "Epoch: [113][0/196]\tTime 5.726 (5.726)\tData 5.694 (5.694)\tLoss 0.6256 (0.6256)\tPrec 74.219% (74.219%)\n",
      "Epoch: [113][100/196]\tTime 0.055 (0.114)\tData 0.001 (0.057)\tLoss 0.6250 (0.6058)\tPrec 76.953% (78.817%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.777 (4.777)\tLoss 0.6470 (0.6470)\tPrec 76.562% (76.562%)\n",
      " * Prec 76.900% \n",
      "best acc: 77.850000\n",
      "Epoch: [114][0/196]\tTime 5.723 (5.723)\tData 5.689 (5.689)\tLoss 0.6856 (0.6856)\tPrec 75.781% (75.781%)\n",
      "Epoch: [114][100/196]\tTime 0.054 (0.112)\tData 0.001 (0.057)\tLoss 0.7399 (0.6128)\tPrec 73.047% (78.694%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.797 (4.797)\tLoss 0.7290 (0.7290)\tPrec 72.656% (72.656%)\n",
      " * Prec 73.950% \n",
      "best acc: 77.850000\n",
      "Epoch: [115][0/196]\tTime 5.843 (5.843)\tData 5.810 (5.810)\tLoss 0.5835 (0.5835)\tPrec 80.859% (80.859%)\n",
      "Epoch: [115][100/196]\tTime 0.090 (0.141)\tData 0.001 (0.058)\tLoss 0.6565 (0.6110)\tPrec 76.562% (78.980%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.759 (4.759)\tLoss 0.6856 (0.6856)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.760% \n",
      "best acc: 77.850000\n",
      "Epoch: [116][0/196]\tTime 5.969 (5.969)\tData 5.922 (5.922)\tLoss 0.6672 (0.6672)\tPrec 78.516% (78.516%)\n",
      "Epoch: [116][100/196]\tTime 0.055 (0.133)\tData 0.001 (0.059)\tLoss 0.6549 (0.6165)\tPrec 76.172% (78.558%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.740 (4.740)\tLoss 0.6521 (0.6521)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.930% \n",
      "best acc: 77.850000\n",
      "Epoch: [117][0/196]\tTime 5.721 (5.721)\tData 5.686 (5.686)\tLoss 0.7223 (0.7223)\tPrec 75.000% (75.000%)\n",
      "Epoch: [117][100/196]\tTime 0.053 (0.115)\tData 0.001 (0.057)\tLoss 0.5665 (0.6113)\tPrec 79.297% (78.794%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.824 (4.824)\tLoss 0.7222 (0.7222)\tPrec 74.609% (74.609%)\n",
      " * Prec 74.860% \n",
      "best acc: 77.850000\n",
      "Epoch: [118][0/196]\tTime 5.972 (5.972)\tData 5.938 (5.938)\tLoss 0.5668 (0.5668)\tPrec 81.250% (81.250%)\n",
      "Epoch: [118][100/196]\tTime 0.090 (0.134)\tData 0.001 (0.059)\tLoss 0.5983 (0.6042)\tPrec 78.125% (78.980%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.727 (4.727)\tLoss 0.6655 (0.6655)\tPrec 78.906% (78.906%)\n",
      " * Prec 76.830% \n",
      "best acc: 77.850000\n",
      "Epoch: [119][0/196]\tTime 5.802 (5.802)\tData 5.751 (5.751)\tLoss 0.6277 (0.6277)\tPrec 79.688% (79.688%)\n",
      "Epoch: [119][100/196]\tTime 0.058 (0.145)\tData 0.001 (0.058)\tLoss 0.6591 (0.6122)\tPrec 74.609% (78.891%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.731 (4.731)\tLoss 0.9560 (0.9560)\tPrec 69.922% (69.922%)\n",
      " * Prec 71.400% \n",
      "best acc: 77.850000\n",
      "Epoch: [120][0/196]\tTime 5.833 (5.833)\tData 5.791 (5.791)\tLoss 0.5415 (0.5415)\tPrec 82.031% (82.031%)\n",
      "Epoch: [120][100/196]\tTime 0.053 (0.116)\tData 0.001 (0.058)\tLoss 0.4664 (0.5997)\tPrec 82.812% (79.281%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.932 (4.932)\tLoss 0.6036 (0.6036)\tPrec 79.297% (79.297%)\n",
      " * Prec 78.150% \n",
      "best acc: 78.150000\n",
      "Epoch: [121][0/196]\tTime 5.669 (5.669)\tData 5.632 (5.632)\tLoss 0.5281 (0.5281)\tPrec 80.859% (80.859%)\n",
      "Epoch: [121][100/196]\tTime 0.089 (0.117)\tData 0.001 (0.056)\tLoss 0.6688 (0.5982)\tPrec 72.656% (79.216%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.661 (4.661)\tLoss 0.6357 (0.6357)\tPrec 78.516% (78.516%)\n",
      " * Prec 78.040% \n",
      "best acc: 78.150000\n",
      "Epoch: [122][0/196]\tTime 5.920 (5.920)\tData 5.886 (5.886)\tLoss 0.5679 (0.5679)\tPrec 76.172% (76.172%)\n",
      "Epoch: [122][100/196]\tTime 0.073 (0.135)\tData 0.001 (0.059)\tLoss 0.5841 (0.5945)\tPrec 79.297% (79.274%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.797 (4.797)\tLoss 0.6258 (0.6258)\tPrec 79.688% (79.688%)\n",
      " * Prec 77.840% \n",
      "best acc: 78.150000\n",
      "Epoch: [123][0/196]\tTime 5.787 (5.787)\tData 5.743 (5.743)\tLoss 0.6131 (0.6131)\tPrec 78.906% (78.906%)\n",
      "Epoch: [123][100/196]\tTime 0.036 (0.103)\tData 0.001 (0.058)\tLoss 0.5614 (0.5984)\tPrec 80.078% (79.146%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.872 (4.872)\tLoss 0.6476 (0.6476)\tPrec 77.344% (77.344%)\n",
      " * Prec 78.150% \n",
      "best acc: 78.150000\n",
      "Epoch: [124][0/196]\tTime 5.653 (5.653)\tData 5.627 (5.627)\tLoss 0.6528 (0.6528)\tPrec 74.219% (74.219%)\n",
      "Epoch: [124][100/196]\tTime 0.062 (0.095)\tData 0.001 (0.056)\tLoss 0.6747 (0.5927)\tPrec 76.562% (79.378%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.849 (4.849)\tLoss 0.6225 (0.6225)\tPrec 78.906% (78.906%)\n",
      " * Prec 77.780% \n",
      "best acc: 78.150000\n",
      "Epoch: [125][0/196]\tTime 5.646 (5.646)\tData 5.614 (5.614)\tLoss 0.6308 (0.6308)\tPrec 74.219% (74.219%)\n",
      "Epoch: [125][100/196]\tTime 0.036 (0.093)\tData 0.001 (0.056)\tLoss 0.6874 (0.5827)\tPrec 75.391% (79.792%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.848 (4.848)\tLoss 0.6112 (0.6112)\tPrec 80.078% (80.078%)\n",
      " * Prec 78.270% \n",
      "best acc: 78.270000\n",
      "Epoch: [126][0/196]\tTime 5.727 (5.727)\tData 5.697 (5.697)\tLoss 0.6503 (0.6503)\tPrec 76.953% (76.953%)\n",
      "Epoch: [126][100/196]\tTime 0.078 (0.094)\tData 0.001 (0.057)\tLoss 0.5889 (0.5939)\tPrec 79.688% (79.448%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.839 (4.839)\tLoss 0.6535 (0.6535)\tPrec 78.125% (78.125%)\n",
      " * Prec 78.110% \n",
      "best acc: 78.270000\n",
      "Epoch: [127][0/196]\tTime 5.587 (5.587)\tData 5.554 (5.554)\tLoss 0.5162 (0.5162)\tPrec 82.812% (82.812%)\n",
      "Epoch: [127][100/196]\tTime 0.095 (0.130)\tData 0.001 (0.056)\tLoss 0.5729 (0.5912)\tPrec 80.078% (79.471%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.707 (4.707)\tLoss 0.6253 (0.6253)\tPrec 78.125% (78.125%)\n",
      " * Prec 78.070% \n",
      "best acc: 78.270000\n",
      "Epoch: [128][0/196]\tTime 5.798 (5.798)\tData 5.751 (5.751)\tLoss 0.6770 (0.6770)\tPrec 74.219% (74.219%)\n",
      "Epoch: [128][100/196]\tTime 0.052 (0.116)\tData 0.001 (0.058)\tLoss 0.6154 (0.5913)\tPrec 79.297% (79.506%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.886 (4.886)\tLoss 0.6664 (0.6664)\tPrec 76.953% (76.953%)\n",
      " * Prec 77.530% \n",
      "best acc: 78.270000\n",
      "Epoch: [129][0/196]\tTime 5.698 (5.698)\tData 5.665 (5.665)\tLoss 0.6348 (0.6348)\tPrec 79.297% (79.297%)\n",
      "Epoch: [129][100/196]\tTime 0.057 (0.110)\tData 0.001 (0.057)\tLoss 0.6459 (0.5942)\tPrec 78.906% (79.278%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.718 (4.718)\tLoss 0.6938 (0.6938)\tPrec 78.516% (78.516%)\n",
      " * Prec 77.470% \n",
      "best acc: 78.270000\n",
      "Epoch: [130][0/196]\tTime 5.655 (5.655)\tData 5.626 (5.626)\tLoss 0.5621 (0.5621)\tPrec 80.469% (80.469%)\n",
      "Epoch: [130][100/196]\tTime 0.091 (0.135)\tData 0.001 (0.056)\tLoss 0.6613 (0.5917)\tPrec 78.906% (79.390%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.771 (4.771)\tLoss 0.6672 (0.6672)\tPrec 76.953% (76.953%)\n",
      " * Prec 77.890% \n",
      "best acc: 78.270000\n",
      "Epoch: [131][0/196]\tTime 5.882 (5.882)\tData 5.841 (5.841)\tLoss 0.5883 (0.5883)\tPrec 80.469% (80.469%)\n",
      "Epoch: [131][100/196]\tTime 0.054 (0.124)\tData 0.001 (0.058)\tLoss 0.5900 (0.5933)\tPrec 80.078% (79.409%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.824 (4.824)\tLoss 0.6864 (0.6864)\tPrec 75.781% (75.781%)\n",
      " * Prec 77.240% \n",
      "best acc: 78.270000\n",
      "Epoch: [132][0/196]\tTime 5.820 (5.820)\tData 5.782 (5.782)\tLoss 0.6220 (0.6220)\tPrec 77.344% (77.344%)\n",
      "Epoch: [132][100/196]\tTime 0.053 (0.116)\tData 0.001 (0.058)\tLoss 0.6330 (0.5985)\tPrec 78.906% (79.239%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.704 (4.704)\tLoss 0.6360 (0.6360)\tPrec 78.516% (78.516%)\n",
      " * Prec 78.000% \n",
      "best acc: 78.270000\n",
      "Epoch: [133][0/196]\tTime 5.798 (5.798)\tData 5.757 (5.757)\tLoss 0.5662 (0.5662)\tPrec 80.078% (80.078%)\n",
      "Epoch: [133][100/196]\tTime 0.086 (0.138)\tData 0.001 (0.058)\tLoss 0.5295 (0.5893)\tPrec 78.906% (79.529%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.659 (4.659)\tLoss 0.6554 (0.6554)\tPrec 77.734% (77.734%)\n",
      " * Prec 77.280% \n",
      "best acc: 78.270000\n",
      "Epoch: [134][0/196]\tTime 5.790 (5.790)\tData 5.743 (5.743)\tLoss 0.6086 (0.6086)\tPrec 78.516% (78.516%)\n",
      "Epoch: [134][100/196]\tTime 0.038 (0.127)\tData 0.001 (0.058)\tLoss 0.4625 (0.5900)\tPrec 83.594% (79.390%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.728 (4.728)\tLoss 0.6767 (0.6767)\tPrec 75.391% (75.391%)\n",
      " * Prec 76.660% \n",
      "best acc: 78.270000\n",
      "Epoch: [135][0/196]\tTime 5.706 (5.706)\tData 5.653 (5.653)\tLoss 0.4590 (0.4590)\tPrec 84.766% (84.766%)\n",
      "Epoch: [135][100/196]\tTime 0.034 (0.103)\tData 0.001 (0.057)\tLoss 0.5669 (0.5865)\tPrec 79.297% (79.846%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.693 (4.693)\tLoss 0.6964 (0.6964)\tPrec 76.953% (76.953%)\n",
      " * Prec 75.550% \n",
      "best acc: 78.270000\n",
      "Epoch: [136][0/196]\tTime 5.697 (5.697)\tData 5.665 (5.665)\tLoss 0.6636 (0.6636)\tPrec 76.172% (76.172%)\n",
      "Epoch: [136][100/196]\tTime 0.032 (0.098)\tData 0.001 (0.057)\tLoss 0.7011 (0.5993)\tPrec 75.781% (79.030%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.860 (4.860)\tLoss 0.6306 (0.6306)\tPrec 77.734% (77.734%)\n",
      " * Prec 77.490% \n",
      "best acc: 78.270000\n",
      "Epoch: [137][0/196]\tTime 5.746 (5.746)\tData 5.718 (5.718)\tLoss 0.5976 (0.5976)\tPrec 80.078% (80.078%)\n",
      "Epoch: [137][100/196]\tTime 0.039 (0.096)\tData 0.001 (0.057)\tLoss 0.5979 (0.5904)\tPrec 79.688% (79.455%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.943 (4.943)\tLoss 0.6160 (0.6160)\tPrec 78.516% (78.516%)\n",
      " * Prec 77.380% \n",
      "best acc: 78.270000\n",
      "Epoch: [138][0/196]\tTime 5.760 (5.760)\tData 5.732 (5.732)\tLoss 0.4575 (0.4575)\tPrec 80.859% (80.859%)\n",
      "Epoch: [138][100/196]\tTime 0.054 (0.095)\tData 0.001 (0.057)\tLoss 0.6047 (0.5886)\tPrec 79.297% (79.541%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.900 (4.900)\tLoss 0.7627 (0.7627)\tPrec 74.219% (74.219%)\n",
      " * Prec 75.040% \n",
      "best acc: 78.270000\n",
      "Epoch: [139][0/196]\tTime 5.642 (5.642)\tData 5.608 (5.608)\tLoss 0.5514 (0.5514)\tPrec 79.297% (79.297%)\n",
      "Epoch: [139][100/196]\tTime 0.075 (0.109)\tData 0.001 (0.056)\tLoss 0.5477 (0.5923)\tPrec 80.859% (79.749%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.790 (4.790)\tLoss 0.6265 (0.6265)\tPrec 78.125% (78.125%)\n",
      " * Prec 78.530% \n",
      "best acc: 78.530000\n",
      "Epoch: [140][0/196]\tTime 5.752 (5.752)\tData 5.718 (5.718)\tLoss 0.6150 (0.6150)\tPrec 77.734% (77.734%)\n",
      "Epoch: [140][100/196]\tTime 0.057 (0.128)\tData 0.001 (0.057)\tLoss 0.5792 (0.5940)\tPrec 80.078% (79.247%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.683 (4.683)\tLoss 0.6306 (0.6306)\tPrec 78.516% (78.516%)\n",
      " * Prec 78.100% \n",
      "best acc: 78.530000\n",
      "Epoch: [141][0/196]\tTime 5.740 (5.740)\tData 5.707 (5.707)\tLoss 0.5024 (0.5024)\tPrec 83.203% (83.203%)\n",
      "Epoch: [141][100/196]\tTime 0.054 (0.111)\tData 0.001 (0.057)\tLoss 0.7065 (0.5924)\tPrec 75.781% (79.455%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.806 (4.806)\tLoss 0.6405 (0.6405)\tPrec 80.078% (80.078%)\n",
      " * Prec 78.040% \n",
      "best acc: 78.530000\n",
      "Epoch: [142][0/196]\tTime 5.621 (5.621)\tData 5.595 (5.595)\tLoss 0.5000 (0.5000)\tPrec 82.422% (82.422%)\n",
      "Epoch: [142][100/196]\tTime 0.089 (0.116)\tData 0.001 (0.056)\tLoss 0.4634 (0.5962)\tPrec 85.547% (79.339%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.745 (4.745)\tLoss 0.7157 (0.7157)\tPrec 76.953% (76.953%)\n",
      " * Prec 75.610% \n",
      "best acc: 78.530000\n",
      "Epoch: [143][0/196]\tTime 5.848 (5.848)\tData 5.810 (5.810)\tLoss 0.6074 (0.6074)\tPrec 80.078% (80.078%)\n",
      "Epoch: [143][100/196]\tTime 0.070 (0.146)\tData 0.001 (0.058)\tLoss 0.6330 (0.5875)\tPrec 79.297% (79.490%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.801 (4.801)\tLoss 0.6388 (0.6388)\tPrec 77.734% (77.734%)\n",
      " * Prec 78.000% \n",
      "best acc: 78.530000\n",
      "Epoch: [144][0/196]\tTime 5.716 (5.716)\tData 5.673 (5.673)\tLoss 0.6525 (0.6525)\tPrec 77.344% (77.344%)\n",
      "Epoch: [144][100/196]\tTime 0.036 (0.127)\tData 0.001 (0.057)\tLoss 0.6663 (0.5914)\tPrec 78.906% (79.862%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.723 (4.723)\tLoss 0.6118 (0.6118)\tPrec 80.469% (80.469%)\n",
      " * Prec 77.990% \n",
      "best acc: 78.530000\n",
      "Epoch: [145][0/196]\tTime 5.576 (5.576)\tData 5.549 (5.549)\tLoss 0.6399 (0.6399)\tPrec 77.734% (77.734%)\n",
      "Epoch: [145][100/196]\tTime 0.041 (0.112)\tData 0.001 (0.056)\tLoss 0.6545 (0.6099)\tPrec 80.078% (78.941%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.972 (4.972)\tLoss 0.6518 (0.6518)\tPrec 77.344% (77.344%)\n",
      " * Prec 77.900% \n",
      "best acc: 78.530000\n",
      "Epoch: [146][0/196]\tTime 5.732 (5.732)\tData 5.701 (5.701)\tLoss 0.5650 (0.5650)\tPrec 81.641% (81.641%)\n",
      "Epoch: [146][100/196]\tTime 0.036 (0.100)\tData 0.001 (0.057)\tLoss 0.5350 (0.5888)\tPrec 80.859% (79.680%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.749 (4.749)\tLoss 0.7114 (0.7114)\tPrec 75.781% (75.781%)\n",
      " * Prec 76.440% \n",
      "best acc: 78.530000\n",
      "Epoch: [147][0/196]\tTime 5.793 (5.793)\tData 5.761 (5.761)\tLoss 0.6297 (0.6297)\tPrec 79.688% (79.688%)\n",
      "Epoch: [147][100/196]\tTime 0.086 (0.108)\tData 0.001 (0.058)\tLoss 0.6223 (0.5874)\tPrec 77.734% (79.641%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.919 (4.919)\tLoss 0.6610 (0.6610)\tPrec 77.344% (77.344%)\n",
      " * Prec 77.600% \n",
      "best acc: 78.530000\n",
      "Epoch: [148][0/196]\tTime 5.595 (5.595)\tData 5.555 (5.555)\tLoss 0.6143 (0.6143)\tPrec 80.078% (80.078%)\n",
      "Epoch: [148][100/196]\tTime 0.094 (0.135)\tData 0.001 (0.056)\tLoss 0.5377 (0.5928)\tPrec 80.859% (79.475%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.688 (4.688)\tLoss 0.6283 (0.6283)\tPrec 78.125% (78.125%)\n",
      " * Prec 78.190% \n",
      "best acc: 78.530000\n",
      "Epoch: [149][0/196]\tTime 5.742 (5.742)\tData 5.715 (5.715)\tLoss 0.5394 (0.5394)\tPrec 80.859% (80.859%)\n",
      "Epoch: [149][100/196]\tTime 0.083 (0.103)\tData 0.001 (0.057)\tLoss 0.6239 (0.5915)\tPrec 75.781% (79.529%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.975 (4.975)\tLoss 0.5979 (0.5979)\tPrec 78.906% (78.906%)\n",
      " * Prec 78.310% \n",
      "best acc: 78.530000\n",
      "Epoch: [150][0/196]\tTime 5.716 (5.716)\tData 5.688 (5.688)\tLoss 0.4892 (0.4892)\tPrec 82.812% (82.812%)\n",
      "Epoch: [150][100/196]\tTime 0.055 (0.107)\tData 0.001 (0.057)\tLoss 0.5667 (0.5878)\tPrec 80.859% (79.730%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.756 (4.756)\tLoss 0.6528 (0.6528)\tPrec 76.953% (76.953%)\n",
      " * Prec 77.350% \n",
      "best acc: 78.530000\n",
      "Epoch: [151][0/196]\tTime 5.797 (5.797)\tData 5.765 (5.765)\tLoss 0.5695 (0.5695)\tPrec 80.469% (80.469%)\n",
      "Epoch: [151][100/196]\tTime 0.090 (0.127)\tData 0.001 (0.058)\tLoss 0.6130 (0.5961)\tPrec 79.688% (79.374%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.764 (4.764)\tLoss 0.6515 (0.6515)\tPrec 76.562% (76.562%)\n",
      " * Prec 76.600% \n",
      "best acc: 78.530000\n",
      "Epoch: [152][0/196]\tTime 5.802 (5.802)\tData 5.762 (5.762)\tLoss 0.5910 (0.5910)\tPrec 79.688% (79.688%)\n",
      "Epoch: [152][100/196]\tTime 0.059 (0.133)\tData 0.001 (0.058)\tLoss 0.7315 (0.5922)\tPrec 73.047% (79.525%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.794 (4.794)\tLoss 0.6160 (0.6160)\tPrec 77.734% (77.734%)\n",
      " * Prec 77.880% \n",
      "best acc: 78.530000\n",
      "Epoch: [153][0/196]\tTime 5.714 (5.714)\tData 5.684 (5.684)\tLoss 0.5508 (0.5508)\tPrec 83.203% (83.203%)\n",
      "Epoch: [153][100/196]\tTime 0.054 (0.114)\tData 0.001 (0.057)\tLoss 0.6253 (0.5929)\tPrec 79.688% (79.332%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.883 (4.883)\tLoss 0.6510 (0.6510)\tPrec 76.562% (76.562%)\n",
      " * Prec 77.660% \n",
      "best acc: 78.530000\n",
      "Epoch: [154][0/196]\tTime 5.764 (5.764)\tData 5.738 (5.738)\tLoss 0.6339 (0.6339)\tPrec 79.297% (79.297%)\n",
      "Epoch: [154][100/196]\tTime 0.093 (0.123)\tData 0.001 (0.057)\tLoss 0.6169 (0.5919)\tPrec 78.125% (79.591%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.754 (4.754)\tLoss 0.6350 (0.6350)\tPrec 78.906% (78.906%)\n",
      " * Prec 78.330% \n",
      "best acc: 78.530000\n",
      "Epoch: [155][0/196]\tTime 5.765 (5.765)\tData 5.730 (5.730)\tLoss 0.6055 (0.6055)\tPrec 80.859% (80.859%)\n",
      "Epoch: [155][100/196]\tTime 0.038 (0.127)\tData 0.001 (0.057)\tLoss 0.4452 (0.5946)\tPrec 85.156% (79.660%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.930 (4.930)\tLoss 0.6464 (0.6464)\tPrec 78.516% (78.516%)\n",
      " * Prec 77.860% \n",
      "best acc: 78.530000\n",
      "Epoch: [156][0/196]\tTime 5.867 (5.867)\tData 5.836 (5.836)\tLoss 0.5637 (0.5637)\tPrec 82.031% (82.031%)\n",
      "Epoch: [156][100/196]\tTime 0.039 (0.095)\tData 0.001 (0.058)\tLoss 0.5914 (0.5858)\tPrec 80.469% (79.703%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.872 (4.872)\tLoss 0.6503 (0.6503)\tPrec 77.734% (77.734%)\n",
      " * Prec 78.050% \n",
      "best acc: 78.530000\n",
      "Epoch: [157][0/196]\tTime 5.503 (5.503)\tData 5.479 (5.479)\tLoss 0.6817 (0.6817)\tPrec 75.000% (75.000%)\n",
      "Epoch: [157][100/196]\tTime 0.061 (0.094)\tData 0.001 (0.055)\tLoss 0.5233 (0.5947)\tPrec 82.031% (79.366%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.844 (4.844)\tLoss 0.6300 (0.6300)\tPrec 78.125% (78.125%)\n",
      " * Prec 77.770% \n",
      "best acc: 78.530000\n",
      "Epoch: [158][0/196]\tTime 5.665 (5.665)\tData 5.639 (5.639)\tLoss 0.5413 (0.5413)\tPrec 80.859% (80.859%)\n",
      "Epoch: [158][100/196]\tTime 0.037 (0.092)\tData 0.001 (0.057)\tLoss 0.5578 (0.5923)\tPrec 78.906% (79.405%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.897 (4.897)\tLoss 0.6401 (0.6401)\tPrec 76.172% (76.172%)\n",
      " * Prec 78.260% \n",
      "best acc: 78.530000\n",
      "Epoch: [159][0/196]\tTime 5.700 (5.700)\tData 5.675 (5.675)\tLoss 0.6155 (0.6155)\tPrec 80.078% (80.078%)\n",
      "Epoch: [159][100/196]\tTime 0.041 (0.092)\tData 0.001 (0.057)\tLoss 0.6707 (0.5957)\tPrec 75.781% (79.641%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.805 (4.805)\tLoss 0.7021 (0.7021)\tPrec 76.953% (76.953%)\n",
      " * Prec 76.750% \n",
      "best acc: 78.530000\n"
     ]
    }
   ],
   "source": [
    "## Start finetuning (training here), and see how much you can recover your accuracy ##\n",
    "## You can change hyper parameters such as epochs or lr ##\n",
    "lr = 0.1\n",
    "weight_decay = 1e-4\n",
    "epochs = 160\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thick-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8348/10000 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check your accuracy again after finetuning\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "driving-tanzania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity for weight_int: 0.6192 (61.92%)\n"
     ]
    }
   ],
   "source": [
    "from models import QuantConv2d\n",
    "\n",
    "#### check global sparsity for weight_int is near 80% #####\n",
    "# Iterate through all QuantConv2d layers and compute weight_int sparsity\n",
    "\n",
    "w_bit = 4\n",
    "total_zeros = 0\n",
    "total_elements = 0\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, QuantConv2d):\n",
    "        weight_q = module.weight_q\n",
    "        w_alpha = module.weight_quant.wgt_alpha\n",
    "        w_delta = w_alpha / (2**(w_bit-1) - 1)\n",
    "        \n",
    "        weight_int = weight_q / w_delta\n",
    "        \n",
    "        zeros = (weight_int == 0).sum().item()\n",
    "        elements = weight_int.nelement()\n",
    "        \n",
    "        total_zeros += zeros\n",
    "        total_elements += elements\n",
    "\n",
    "global_sparsity = total_zeros / total_elements\n",
    "print(f\"Global sparsity for weight_int: {global_sparsity:.4f} ({global_sparsity*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-peeing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.9204, device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-excuse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
