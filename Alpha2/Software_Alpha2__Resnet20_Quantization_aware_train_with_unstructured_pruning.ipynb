{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "radical-fifty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "ResNet_Cifar(\n",
      "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): QuantConv2d(\n",
      "          32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False\n",
      "          (weight_quant): weight_quantize_fn()\n",
      "        )\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (conv2): QuantConv2d(\n",
      "        64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "        (weight_quant): weight_quantize_fn()\n",
      "      )\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AvgPool2d(kernel_size=8, stride=1, padding=0)\n",
      "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "from tensorboardX import SummaryWriter      \n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "    \n",
    "    \n",
    "batch_size = 256\n",
    "model_name = \"Resnet20_quant_unstructure_pruning\"\n",
    "model = resnet20_quant()\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "            \n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "        \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [80, 120]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1        \n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "#all_params = checkpoint['state_dict']\n",
    "#model.load_state_dict(all_params, strict=False)\n",
    "#criterion = nn.CrossEntropyLoss().cuda()\n",
    "#validate(testloader, model, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying unstructured pruning to layer1.0.conv1\n",
      "Applying unstructured pruning to layer1.0.conv2\n",
      "Applying unstructured pruning to layer1.1.conv1\n",
      "Applying unstructured pruning to layer1.1.conv2\n",
      "Applying unstructured pruning to layer1.2.conv1\n",
      "Applying unstructured pruning to layer1.2.conv2\n",
      "Applying unstructured pruning to layer2.0.conv1\n",
      "Applying unstructured pruning to layer2.0.conv2\n",
      "Applying unstructured pruning to layer2.0.downsample.0\n",
      "Applying unstructured pruning to layer2.1.conv1\n",
      "Applying unstructured pruning to layer2.1.conv2\n",
      "Applying unstructured pruning to layer2.2.conv1\n",
      "Applying unstructured pruning to layer2.2.conv2\n",
      "Applying unstructured pruning to layer3.0.conv1\n",
      "Applying unstructured pruning to layer3.0.conv2\n",
      "Applying unstructured pruning to layer3.0.downsample.0\n",
      "Applying unstructured pruning to layer3.1.conv1\n",
      "Applying unstructured pruning to layer3.1.conv2\n",
      "Applying unstructured pruning to layer3.2.conv1\n",
      "Applying unstructured pruning to layer3.2.conv2\n",
      "\n",
      "Test set: Accuracy: 8994/10000 (90%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from models import QuantConv2d\n",
    "\n",
    "PATH = \"result/{}/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH.format(model_name))\n",
    "\n",
    "# Apply pruning structure to model before loading checkpoint\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, QuantConv2d):\n",
    "        print(\"Applying unstructured pruning to {}\".format(name))\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.8)\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "present-coral",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Prune all the QuantConv2D layers' 90% weights with 1) unstructured, and 2) structured manner.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aea7b840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pruning 80% weights in layer1.0.conv1\n",
      "Pruning 80% weights in layer1.0.conv2\n",
      "Pruning 80% weights in layer1.1.conv1\n",
      "Pruning 80% weights in layer1.1.conv2\n",
      "Pruning 80% weights in layer1.2.conv1\n",
      "Pruning 80% weights in layer1.2.conv2\n",
      "Pruning 80% weights in layer2.0.conv1\n",
      "Pruning 80% weights in layer2.0.conv2\n",
      "Pruning 80% weights in layer2.0.downsample.0\n",
      "Pruning 80% weights in layer2.1.conv1\n",
      "Pruning 80% weights in layer2.1.conv2\n",
      "Pruning 80% weights in layer2.2.conv1\n",
      "Pruning 80% weights in layer2.2.conv2\n",
      "Pruning 80% weights in layer3.0.conv1\n",
      "Pruning 80% weights in layer3.0.conv2\n",
      "Pruning 80% weights in layer3.0.downsample.0\n",
      "Pruning 80% weights in layer3.1.conv1\n",
      "Pruning 80% weights in layer3.1.conv2\n",
      "Pruning 80% weights in layer3.2.conv1\n",
      "Pruning 80% weights in layer3.2.conv2\n"
     ]
    }
   ],
   "source": [
    "# Unstructured pruning with 80% sparsity\n",
    "\n",
    "import torch.nn.utils.prune as prune\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, QuantConv2d):\n",
    "        print(\"Pruning 80% weights in {}\".format(name))\n",
    "        prune.l1_unstructured(module, name='weight', amount=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e8aedb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fourth-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access a QuantConv2d layer in the model (e.g., layer3[2].conv2)\n",
    "print(list(model.layer3[2].conv2.named_parameters())) # check whether there is mask, weight_org, ...\n",
    "print(model.layer3[2].conv2.weight) # check whether there are many zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ceramic-nigeria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.8000, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "### Check sparsity ###\n",
    "mask1 = model.layer3[2].conv2.weight_mask\n",
    "sparsity_mask1 = (mask1 == 0).sum() / mask1.nelement()\n",
    "\n",
    "print(\"Sparsity level: \", sparsity_mask1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acquired-vampire",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 1000/10000 (10%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check accuracy after pruning\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "spoken-worst",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/196]\tTime 4.744 (4.744)\tData 4.622 (4.622)\tLoss 1.4065 (1.4065)\tPrec 60.938% (60.938%)\n",
      "Epoch: [0][100/196]\tTime 0.038 (0.069)\tData 0.001 (0.046)\tLoss 0.3271 (0.5255)\tPrec 88.672% (82.085%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.816 (3.816)\tLoss 0.4900 (0.4900)\tPrec 83.594% (83.594%)\n",
      " * Prec 84.270% \n",
      "best acc: 84.270000\n",
      "Epoch: [1][0/196]\tTime 4.460 (4.460)\tData 4.436 (4.436)\tLoss 0.3332 (0.3332)\tPrec 88.672% (88.672%)\n",
      "Epoch: [1][100/196]\tTime 0.036 (0.066)\tData 0.001 (0.044)\tLoss 0.3160 (0.3268)\tPrec 88.281% (88.614%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.878 (3.878)\tLoss 0.5823 (0.5823)\tPrec 81.641% (81.641%)\n",
      " * Prec 84.020% \n",
      "best acc: 84.270000\n",
      "Epoch: [2][0/196]\tTime 4.520 (4.520)\tData 4.502 (4.502)\tLoss 0.2919 (0.2919)\tPrec 89.062% (89.062%)\n",
      "Epoch: [2][100/196]\tTime 0.038 (0.076)\tData 0.001 (0.045)\tLoss 0.3009 (0.2911)\tPrec 89.453% (89.720%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.843 (3.843)\tLoss 0.6630 (0.6630)\tPrec 82.031% (82.031%)\n",
      " * Prec 82.010% \n",
      "best acc: 84.270000\n",
      "Epoch: [3][0/196]\tTime 4.339 (4.339)\tData 4.315 (4.315)\tLoss 0.3113 (0.3113)\tPrec 88.281% (88.281%)\n",
      "Epoch: [3][100/196]\tTime 0.020 (0.063)\tData 0.001 (0.043)\tLoss 0.2371 (0.2782)\tPrec 91.797% (90.231%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.754 (3.754)\tLoss 0.9007 (0.9007)\tPrec 74.219% (74.219%)\n",
      " * Prec 76.200% \n",
      "best acc: 84.270000\n",
      "Epoch: [4][0/196]\tTime 4.420 (4.420)\tData 4.396 (4.396)\tLoss 0.2600 (0.2600)\tPrec 90.234% (90.234%)\n",
      "Epoch: [4][100/196]\tTime 0.020 (0.066)\tData 0.001 (0.044)\tLoss 0.2828 (0.2624)\tPrec 88.672% (90.582%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.842 (3.842)\tLoss 0.7173 (0.7173)\tPrec 82.031% (82.031%)\n",
      " * Prec 81.750% \n",
      "best acc: 84.270000\n",
      "Epoch: [5][0/196]\tTime 4.393 (4.393)\tData 4.365 (4.365)\tLoss 0.2972 (0.2972)\tPrec 89.453% (89.453%)\n",
      "Epoch: [5][100/196]\tTime 0.020 (0.066)\tData 0.001 (0.044)\tLoss 0.2758 (0.2642)\tPrec 90.625% (90.594%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.923 (3.923)\tLoss 0.6125 (0.6125)\tPrec 78.516% (78.516%)\n",
      " * Prec 81.880% \n",
      "best acc: 84.270000\n",
      "Epoch: [6][0/196]\tTime 4.663 (4.663)\tData 4.638 (4.638)\tLoss 0.2610 (0.2610)\tPrec 91.016% (91.016%)\n",
      "Epoch: [6][100/196]\tTime 0.023 (0.069)\tData 0.001 (0.047)\tLoss 0.2761 (0.2452)\tPrec 92.188% (91.186%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.913 (3.913)\tLoss 1.1418 (1.1418)\tPrec 62.891% (62.891%)\n",
      " * Prec 66.180% \n",
      "best acc: 84.270000\n",
      "Epoch: [7][0/196]\tTime 4.471 (4.471)\tData 4.446 (4.446)\tLoss 0.2501 (0.2501)\tPrec 91.797% (91.797%)\n",
      "Epoch: [7][100/196]\tTime 0.020 (0.069)\tData 0.001 (0.045)\tLoss 0.2013 (0.2518)\tPrec 93.359% (91.197%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.923 (3.923)\tLoss 0.6976 (0.6976)\tPrec 75.781% (75.781%)\n",
      " * Prec 78.250% \n",
      "best acc: 84.270000\n",
      "Epoch: [8][0/196]\tTime 5.424 (5.424)\tData 5.396 (5.396)\tLoss 0.2201 (0.2201)\tPrec 91.797% (91.797%)\n",
      "Epoch: [8][100/196]\tTime 0.027 (0.084)\tData 0.001 (0.054)\tLoss 0.2651 (0.2375)\tPrec 91.016% (91.662%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.913 (4.913)\tLoss 0.4808 (0.4808)\tPrec 82.812% (82.812%)\n",
      " * Prec 85.960% \n",
      "best acc: 85.960000\n",
      "Epoch: [9][0/196]\tTime 6.016 (6.016)\tData 5.987 (5.987)\tLoss 0.2811 (0.2811)\tPrec 91.406% (91.406%)\n",
      "Epoch: [9][100/196]\tTime 0.027 (0.089)\tData 0.001 (0.060)\tLoss 0.1870 (0.2406)\tPrec 92.578% (91.538%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 5.004 (5.004)\tLoss 0.6560 (0.6560)\tPrec 82.031% (82.031%)\n",
      " * Prec 83.490% \n",
      "best acc: 85.960000\n",
      "Epoch: [10][0/196]\tTime 5.941 (5.941)\tData 5.901 (5.901)\tLoss 0.2177 (0.2177)\tPrec 90.625% (90.625%)\n",
      "Epoch: [10][100/196]\tTime 0.025 (0.084)\tData 0.000 (0.059)\tLoss 0.2556 (0.2337)\tPrec 92.188% (91.696%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 5.023 (5.023)\tLoss 0.4372 (0.4372)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.910% \n",
      "best acc: 85.960000\n",
      "Epoch: [11][0/196]\tTime 5.982 (5.982)\tData 5.955 (5.955)\tLoss 0.2919 (0.2919)\tPrec 88.672% (88.672%)\n",
      "Epoch: [11][100/196]\tTime 0.024 (0.085)\tData 0.001 (0.060)\tLoss 0.2436 (0.2281)\tPrec 91.016% (92.060%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.949 (4.949)\tLoss 0.4875 (0.4875)\tPrec 83.984% (83.984%)\n",
      " * Prec 85.220% \n",
      "best acc: 85.960000\n",
      "Epoch: [12][0/196]\tTime 5.899 (5.899)\tData 5.871 (5.871)\tLoss 0.2698 (0.2698)\tPrec 89.844% (89.844%)\n",
      "Epoch: [12][100/196]\tTime 0.025 (0.086)\tData 0.001 (0.059)\tLoss 0.2606 (0.2373)\tPrec 90.234% (91.545%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.944 (4.944)\tLoss 0.5291 (0.5291)\tPrec 82.812% (82.812%)\n",
      " * Prec 83.940% \n",
      "best acc: 85.960000\n",
      "Epoch: [13][0/196]\tTime 5.827 (5.827)\tData 5.800 (5.800)\tLoss 0.2656 (0.2656)\tPrec 90.625% (90.625%)\n",
      "Epoch: [13][100/196]\tTime 0.024 (0.086)\tData 0.001 (0.058)\tLoss 0.2653 (0.2258)\tPrec 91.016% (92.060%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.820 (4.820)\tLoss 1.2156 (1.2156)\tPrec 71.875% (71.875%)\n",
      " * Prec 75.180% \n",
      "best acc: 85.960000\n",
      "Epoch: [14][0/196]\tTime 5.671 (5.671)\tData 5.644 (5.644)\tLoss 0.2661 (0.2661)\tPrec 89.453% (89.453%)\n",
      "Epoch: [14][100/196]\tTime 0.029 (0.087)\tData 0.001 (0.057)\tLoss 0.2715 (0.2319)\tPrec 91.797% (91.824%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.811 (4.811)\tLoss 0.9180 (0.9180)\tPrec 73.828% (73.828%)\n",
      " * Prec 79.640% \n",
      "best acc: 85.960000\n",
      "Epoch: [15][0/196]\tTime 5.987 (5.987)\tData 5.958 (5.958)\tLoss 0.2029 (0.2029)\tPrec 92.188% (92.188%)\n",
      "Epoch: [15][100/196]\tTime 0.059 (0.086)\tData 0.001 (0.060)\tLoss 0.2335 (0.2231)\tPrec 91.016% (92.133%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.654 (4.654)\tLoss 0.4620 (0.4620)\tPrec 84.766% (84.766%)\n",
      " * Prec 85.250% \n",
      "best acc: 85.960000\n",
      "Epoch: [16][0/196]\tTime 5.983 (5.983)\tData 5.960 (5.960)\tLoss 0.1798 (0.1798)\tPrec 95.703% (95.703%)\n",
      "Epoch: [16][100/196]\tTime 0.055 (0.105)\tData 0.001 (0.060)\tLoss 0.1911 (0.2256)\tPrec 93.359% (92.029%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.868 (3.868)\tLoss 0.4037 (0.4037)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.600% \n",
      "best acc: 86.600000\n",
      "Epoch: [17][0/196]\tTime 4.779 (4.779)\tData 4.737 (4.737)\tLoss 0.2224 (0.2224)\tPrec 91.016% (91.016%)\n",
      "Epoch: [17][100/196]\tTime 0.019 (0.098)\tData 0.000 (0.048)\tLoss 0.2497 (0.2280)\tPrec 89.844% (92.064%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.763 (4.763)\tLoss 1.0821 (1.0821)\tPrec 74.219% (74.219%)\n",
      " * Prec 76.240% \n",
      "best acc: 86.600000\n",
      "Epoch: [18][0/196]\tTime 5.553 (5.553)\tData 5.518 (5.518)\tLoss 0.2559 (0.2559)\tPrec 91.406% (91.406%)\n",
      "Epoch: [18][100/196]\tTime 0.026 (0.092)\tData 0.001 (0.055)\tLoss 0.1927 (0.2319)\tPrec 91.016% (91.766%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.698 (4.698)\tLoss 0.8020 (0.8020)\tPrec 78.125% (78.125%)\n",
      " * Prec 76.980% \n",
      "best acc: 86.600000\n",
      "Epoch: [19][0/196]\tTime 5.790 (5.790)\tData 5.763 (5.763)\tLoss 0.2626 (0.2626)\tPrec 89.453% (89.453%)\n",
      "Epoch: [19][100/196]\tTime 0.022 (0.082)\tData 0.001 (0.058)\tLoss 0.1724 (0.2211)\tPrec 94.141% (92.265%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.830 (4.830)\tLoss 0.6579 (0.6579)\tPrec 76.953% (76.953%)\n",
      " * Prec 79.290% \n",
      "best acc: 86.600000\n",
      "Epoch: [20][0/196]\tTime 5.886 (5.886)\tData 5.864 (5.864)\tLoss 0.2077 (0.2077)\tPrec 93.359% (93.359%)\n",
      "Epoch: [20][100/196]\tTime 0.028 (0.084)\tData 0.001 (0.059)\tLoss 0.2455 (0.2270)\tPrec 91.406% (91.990%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.947 (4.947)\tLoss 0.4227 (0.4227)\tPrec 86.719% (86.719%)\n",
      " * Prec 85.650% \n",
      "best acc: 86.600000\n",
      "Epoch: [21][0/196]\tTime 5.761 (5.761)\tData 5.735 (5.735)\tLoss 0.1485 (0.1485)\tPrec 93.750% (93.750%)\n",
      "Epoch: [21][100/196]\tTime 0.029 (0.083)\tData 0.001 (0.057)\tLoss 0.2086 (0.2246)\tPrec 92.969% (91.994%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.846 (4.846)\tLoss 0.4472 (0.4472)\tPrec 84.375% (84.375%)\n",
      " * Prec 86.500% \n",
      "best acc: 86.600000\n",
      "Epoch: [22][0/196]\tTime 4.545 (4.545)\tData 4.523 (4.523)\tLoss 0.2036 (0.2036)\tPrec 94.531% (94.531%)\n",
      "Epoch: [22][100/196]\tTime 0.020 (0.065)\tData 0.001 (0.045)\tLoss 0.1972 (0.2242)\tPrec 93.359% (92.029%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.803 (3.803)\tLoss 0.4056 (0.4056)\tPrec 83.594% (83.594%)\n",
      " * Prec 86.540% \n",
      "best acc: 86.600000\n",
      "Epoch: [23][0/196]\tTime 4.877 (4.877)\tData 4.854 (4.854)\tLoss 0.1838 (0.1838)\tPrec 91.016% (91.016%)\n",
      "Epoch: [23][100/196]\tTime 0.020 (0.073)\tData 0.001 (0.049)\tLoss 0.1794 (0.2185)\tPrec 94.141% (92.191%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.768 (3.768)\tLoss 0.4264 (0.4264)\tPrec 84.766% (84.766%)\n",
      " * Prec 86.520% \n",
      "best acc: 86.600000\n",
      "Epoch: [24][0/196]\tTime 4.393 (4.393)\tData 4.372 (4.372)\tLoss 0.1938 (0.1938)\tPrec 93.750% (93.750%)\n",
      "Epoch: [24][100/196]\tTime 0.020 (0.066)\tData 0.001 (0.044)\tLoss 0.2293 (0.2305)\tPrec 91.797% (91.762%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.717 (3.717)\tLoss 0.4679 (0.4679)\tPrec 83.203% (83.203%)\n",
      " * Prec 85.830% \n",
      "best acc: 86.600000\n",
      "Epoch: [25][0/196]\tTime 4.440 (4.440)\tData 4.413 (4.413)\tLoss 0.2161 (0.2161)\tPrec 91.797% (91.797%)\n",
      "Epoch: [25][100/196]\tTime 0.020 (0.067)\tData 0.001 (0.044)\tLoss 0.2183 (0.2316)\tPrec 92.578% (91.797%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.804 (3.804)\tLoss 0.4914 (0.4914)\tPrec 85.156% (85.156%)\n",
      " * Prec 84.760% \n",
      "best acc: 86.600000\n",
      "Epoch: [26][0/196]\tTime 4.361 (4.361)\tData 4.339 (4.339)\tLoss 0.2175 (0.2175)\tPrec 91.797% (91.797%)\n",
      "Epoch: [26][100/196]\tTime 0.021 (0.063)\tData 0.001 (0.044)\tLoss 0.1707 (0.2276)\tPrec 94.922% (92.021%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.927 (3.927)\tLoss 0.5828 (0.5828)\tPrec 80.859% (80.859%)\n",
      " * Prec 84.950% \n",
      "best acc: 86.600000\n",
      "Epoch: [27][0/196]\tTime 4.286 (4.286)\tData 4.246 (4.246)\tLoss 0.2221 (0.2221)\tPrec 92.188% (92.188%)\n",
      "Epoch: [27][100/196]\tTime 0.020 (0.078)\tData 0.001 (0.043)\tLoss 0.2154 (0.2304)\tPrec 92.969% (91.739%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.804 (3.804)\tLoss 0.5470 (0.5470)\tPrec 80.078% (80.078%)\n",
      " * Prec 83.750% \n",
      "best acc: 86.600000\n",
      "Epoch: [28][0/196]\tTime 4.530 (4.530)\tData 4.503 (4.503)\tLoss 0.3185 (0.3185)\tPrec 89.453% (89.453%)\n",
      "Epoch: [28][100/196]\tTime 0.065 (0.085)\tData 0.001 (0.045)\tLoss 0.2035 (0.2270)\tPrec 93.359% (91.936%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.710 (4.710)\tLoss 0.4970 (0.4970)\tPrec 85.547% (85.547%)\n",
      " * Prec 87.190% \n",
      "best acc: 87.190000\n",
      "Epoch: [29][0/196]\tTime 5.832 (5.832)\tData 5.808 (5.808)\tLoss 0.2581 (0.2581)\tPrec 91.406% (91.406%)\n",
      "Epoch: [29][100/196]\tTime 0.040 (0.098)\tData 0.001 (0.058)\tLoss 0.2621 (0.2342)\tPrec 87.891% (91.716%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.866 (3.866)\tLoss 0.5145 (0.5145)\tPrec 82.422% (82.422%)\n",
      " * Prec 85.090% \n",
      "best acc: 87.190000\n",
      "Epoch: [30][0/196]\tTime 4.342 (4.342)\tData 4.317 (4.317)\tLoss 0.2503 (0.2503)\tPrec 91.016% (91.016%)\n",
      "Epoch: [30][100/196]\tTime 0.038 (0.080)\tData 0.001 (0.043)\tLoss 0.2508 (0.2248)\tPrec 90.625% (91.979%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.772 (3.772)\tLoss 1.7762 (1.7762)\tPrec 62.500% (62.500%)\n",
      " * Prec 64.760% \n",
      "best acc: 87.190000\n",
      "Epoch: [31][0/196]\tTime 4.294 (4.294)\tData 4.264 (4.264)\tLoss 0.3082 (0.3082)\tPrec 89.062% (89.062%)\n",
      "Epoch: [31][100/196]\tTime 0.052 (0.079)\tData 0.001 (0.043)\tLoss 0.2339 (0.2269)\tPrec 92.188% (92.029%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.761 (3.761)\tLoss 0.8767 (0.8767)\tPrec 71.875% (71.875%)\n",
      " * Prec 73.930% \n",
      "best acc: 87.190000\n",
      "Epoch: [32][0/196]\tTime 4.376 (4.376)\tData 4.345 (4.345)\tLoss 0.2629 (0.2629)\tPrec 89.844% (89.844%)\n",
      "Epoch: [32][100/196]\tTime 0.059 (0.099)\tData 0.001 (0.044)\tLoss 0.2318 (0.2276)\tPrec 91.797% (92.102%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.798 (3.798)\tLoss 6.2440 (6.2440)\tPrec 29.297% (29.297%)\n",
      " * Prec 35.280% \n",
      "best acc: 87.190000\n",
      "Epoch: [33][0/196]\tTime 4.268 (4.268)\tData 4.240 (4.240)\tLoss 0.1766 (0.1766)\tPrec 94.922% (94.922%)\n",
      "Epoch: [33][100/196]\tTime 0.037 (0.093)\tData 0.001 (0.043)\tLoss 0.3093 (0.2246)\tPrec 91.406% (92.044%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.931 (3.931)\tLoss 0.6791 (0.6791)\tPrec 77.344% (77.344%)\n",
      " * Prec 79.980% \n",
      "best acc: 87.190000\n",
      "Epoch: [34][0/196]\tTime 4.609 (4.609)\tData 4.578 (4.578)\tLoss 0.2277 (0.2277)\tPrec 92.188% (92.188%)\n",
      "Epoch: [34][100/196]\tTime 0.020 (0.066)\tData 0.001 (0.046)\tLoss 0.2437 (0.2278)\tPrec 89.062% (91.863%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.799 (3.799)\tLoss 0.6624 (0.6624)\tPrec 76.172% (76.172%)\n",
      " * Prec 78.900% \n",
      "best acc: 87.190000\n",
      "Epoch: [35][0/196]\tTime 4.485 (4.485)\tData 4.460 (4.460)\tLoss 0.2497 (0.2497)\tPrec 90.625% (90.625%)\n",
      "Epoch: [35][100/196]\tTime 0.020 (0.065)\tData 0.000 (0.045)\tLoss 0.2057 (0.2272)\tPrec 90.625% (91.971%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.962 (3.962)\tLoss 0.5282 (0.5282)\tPrec 82.422% (82.422%)\n",
      " * Prec 85.290% \n",
      "best acc: 87.190000\n",
      "Epoch: [36][0/196]\tTime 4.296 (4.296)\tData 4.276 (4.276)\tLoss 0.1964 (0.1964)\tPrec 92.578% (92.578%)\n",
      "Epoch: [36][100/196]\tTime 0.019 (0.062)\tData 0.001 (0.043)\tLoss 0.2227 (0.2183)\tPrec 91.016% (92.265%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.787 (3.787)\tLoss 0.7314 (0.7314)\tPrec 78.906% (78.906%)\n",
      " * Prec 82.060% \n",
      "best acc: 87.190000\n",
      "Epoch: [37][0/196]\tTime 4.126 (4.126)\tData 4.106 (4.106)\tLoss 0.2310 (0.2310)\tPrec 89.844% (89.844%)\n",
      "Epoch: [37][100/196]\tTime 0.020 (0.061)\tData 0.001 (0.041)\tLoss 0.2196 (0.2269)\tPrec 92.578% (92.017%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.800 (3.800)\tLoss 0.4453 (0.4453)\tPrec 83.594% (83.594%)\n",
      " * Prec 86.410% \n",
      "best acc: 87.190000\n",
      "Epoch: [38][0/196]\tTime 4.254 (4.254)\tData 4.233 (4.233)\tLoss 0.2146 (0.2146)\tPrec 90.234% (90.234%)\n",
      "Epoch: [38][100/196]\tTime 0.019 (0.062)\tData 0.001 (0.042)\tLoss 0.2246 (0.2245)\tPrec 92.188% (92.060%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.729 (3.729)\tLoss 0.4082 (0.4082)\tPrec 85.156% (85.156%)\n",
      " * Prec 86.340% \n",
      "best acc: 87.190000\n",
      "Epoch: [39][0/196]\tTime 4.282 (4.282)\tData 4.262 (4.262)\tLoss 0.1693 (0.1693)\tPrec 94.922% (94.922%)\n",
      "Epoch: [39][100/196]\tTime 0.019 (0.062)\tData 0.001 (0.043)\tLoss 0.2196 (0.2219)\tPrec 90.234% (92.064%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.852 (3.852)\tLoss 0.5308 (0.5308)\tPrec 80.469% (80.469%)\n",
      " * Prec 83.810% \n",
      "best acc: 87.190000\n",
      "Epoch: [40][0/196]\tTime 4.445 (4.445)\tData 4.419 (4.419)\tLoss 0.1931 (0.1931)\tPrec 91.797% (91.797%)\n",
      "Epoch: [40][100/196]\tTime 0.019 (0.064)\tData 0.001 (0.044)\tLoss 0.2005 (0.2310)\tPrec 91.797% (91.681%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.716 (3.716)\tLoss 0.6014 (0.6014)\tPrec 82.031% (82.031%)\n",
      " * Prec 82.610% \n",
      "best acc: 87.190000\n",
      "Epoch: [41][0/196]\tTime 4.229 (4.229)\tData 4.198 (4.198)\tLoss 0.2266 (0.2266)\tPrec 92.969% (92.969%)\n",
      "Epoch: [41][100/196]\tTime 0.020 (0.062)\tData 0.001 (0.042)\tLoss 0.1800 (0.2287)\tPrec 94.141% (91.990%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.781 (3.781)\tLoss 0.5816 (0.5816)\tPrec 81.641% (81.641%)\n",
      " * Prec 83.550% \n",
      "best acc: 87.190000\n",
      "Epoch: [42][0/196]\tTime 4.382 (4.382)\tData 4.354 (4.354)\tLoss 0.1701 (0.1701)\tPrec 94.531% (94.531%)\n",
      "Epoch: [42][100/196]\tTime 0.020 (0.065)\tData 0.001 (0.044)\tLoss 0.2773 (0.2220)\tPrec 89.844% (92.269%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.745 (3.745)\tLoss 0.6203 (0.6203)\tPrec 78.906% (78.906%)\n",
      " * Prec 81.560% \n",
      "best acc: 87.190000\n",
      "Epoch: [43][0/196]\tTime 4.476 (4.476)\tData 4.441 (4.441)\tLoss 0.3129 (0.3129)\tPrec 89.062% (89.062%)\n",
      "Epoch: [43][100/196]\tTime 0.040 (0.077)\tData 0.001 (0.045)\tLoss 0.2261 (0.2288)\tPrec 91.016% (91.824%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.068 (4.068)\tLoss 0.5233 (0.5233)\tPrec 85.938% (85.938%)\n",
      " * Prec 86.010% \n",
      "best acc: 87.190000\n",
      "Epoch: [44][0/196]\tTime 4.491 (4.491)\tData 4.455 (4.455)\tLoss 0.2377 (0.2377)\tPrec 92.188% (92.188%)\n",
      "Epoch: [44][100/196]\tTime 0.058 (0.103)\tData 0.001 (0.045)\tLoss 0.1844 (0.2155)\tPrec 92.578% (92.350%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 3.865 (3.865)\tLoss 0.3202 (0.3202)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.410% \n",
      "best acc: 87.190000\n",
      "Epoch: [45][0/196]\tTime 4.469 (4.469)\tData 4.419 (4.419)\tLoss 0.2080 (0.2080)\tPrec 92.188% (92.188%)\n",
      "Epoch: [45][100/196]\tTime 0.094 (0.105)\tData 0.001 (0.044)\tLoss 0.2083 (0.2292)\tPrec 92.578% (91.774%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.021 (4.021)\tLoss 0.6310 (0.6310)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.460% \n",
      "best acc: 87.190000\n",
      "Epoch: [46][0/196]\tTime 5.696 (5.696)\tData 5.657 (5.657)\tLoss 0.2814 (0.2814)\tPrec 89.062% (89.062%)\n",
      "Epoch: [46][100/196]\tTime 0.078 (0.126)\tData 0.001 (0.057)\tLoss 0.2539 (0.2282)\tPrec 89.844% (91.890%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 5.029 (5.029)\tLoss 0.4559 (0.4559)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.790% \n",
      "best acc: 87.190000\n",
      "Epoch: [47][0/196]\tTime 5.513 (5.513)\tData 5.470 (5.470)\tLoss 0.1504 (0.1504)\tPrec 96.484% (96.484%)\n",
      "Epoch: [47][100/196]\tTime 0.055 (0.128)\tData 0.001 (0.055)\tLoss 0.2268 (0.2198)\tPrec 91.406% (92.265%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.820 (4.820)\tLoss 1.2586 (1.2586)\tPrec 72.266% (72.266%)\n",
      " * Prec 75.690% \n",
      "best acc: 87.190000\n",
      "Epoch: [48][0/196]\tTime 5.828 (5.828)\tData 5.800 (5.800)\tLoss 0.1991 (0.1991)\tPrec 91.797% (91.797%)\n",
      "Epoch: [48][100/196]\tTime 0.057 (0.098)\tData 0.001 (0.058)\tLoss 0.1956 (0.2236)\tPrec 92.578% (92.106%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.919 (4.919)\tLoss 0.9275 (0.9275)\tPrec 76.172% (76.172%)\n",
      " * Prec 76.400% \n",
      "best acc: 87.190000\n",
      "Epoch: [49][0/196]\tTime 5.683 (5.683)\tData 5.654 (5.654)\tLoss 0.1679 (0.1679)\tPrec 93.359% (93.359%)\n",
      "Epoch: [49][100/196]\tTime 0.060 (0.108)\tData 0.001 (0.057)\tLoss 0.2528 (0.2256)\tPrec 91.797% (91.747%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.878 (4.878)\tLoss 0.5367 (0.5367)\tPrec 82.031% (82.031%)\n",
      " * Prec 82.140% \n",
      "best acc: 87.190000\n",
      "Epoch: [50][0/196]\tTime 5.741 (5.741)\tData 5.715 (5.715)\tLoss 0.2035 (0.2035)\tPrec 92.969% (92.969%)\n",
      "Epoch: [50][100/196]\tTime 0.069 (0.104)\tData 0.001 (0.057)\tLoss 0.1820 (0.2194)\tPrec 92.578% (92.207%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.756 (4.756)\tLoss 0.4552 (0.4552)\tPrec 82.812% (82.812%)\n",
      " * Prec 83.730% \n",
      "best acc: 87.190000\n",
      "Epoch: [51][0/196]\tTime 5.816 (5.816)\tData 5.784 (5.784)\tLoss 0.2316 (0.2316)\tPrec 91.406% (91.406%)\n",
      "Epoch: [51][100/196]\tTime 0.067 (0.125)\tData 0.001 (0.058)\tLoss 0.2689 (0.2284)\tPrec 91.406% (91.990%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 5.076 (5.076)\tLoss 1.1116 (1.1116)\tPrec 73.828% (73.828%)\n",
      " * Prec 76.340% \n",
      "best acc: 87.190000\n",
      "Epoch: [52][0/196]\tTime 5.742 (5.742)\tData 5.706 (5.706)\tLoss 0.2570 (0.2570)\tPrec 91.016% (91.016%)\n",
      "Epoch: [52][100/196]\tTime 0.037 (0.104)\tData 0.001 (0.057)\tLoss 0.3106 (0.2174)\tPrec 90.234% (92.195%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.718 (4.718)\tLoss 1.6258 (1.6258)\tPrec 68.750% (68.750%)\n",
      " * Prec 66.620% \n",
      "best acc: 87.190000\n",
      "Epoch: [53][0/196]\tTime 5.574 (5.574)\tData 5.550 (5.550)\tLoss 0.3124 (0.3124)\tPrec 87.891% (87.891%)\n",
      "Epoch: [53][100/196]\tTime 0.064 (0.089)\tData 0.001 (0.056)\tLoss 0.2301 (0.2274)\tPrec 90.234% (92.025%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.829 (4.829)\tLoss 0.5606 (0.5606)\tPrec 80.469% (80.469%)\n",
      " * Prec 81.630% \n",
      "best acc: 87.190000\n",
      "Epoch: [54][0/196]\tTime 5.602 (5.602)\tData 5.574 (5.574)\tLoss 0.1967 (0.1967)\tPrec 93.750% (93.750%)\n",
      "Epoch: [54][100/196]\tTime 0.037 (0.089)\tData 0.001 (0.056)\tLoss 0.2221 (0.2205)\tPrec 90.625% (92.253%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.690 (4.690)\tLoss 0.5478 (0.5478)\tPrec 79.297% (79.297%)\n",
      " * Prec 82.350% \n",
      "best acc: 87.190000\n",
      "Epoch: [55][0/196]\tTime 5.485 (5.485)\tData 5.459 (5.459)\tLoss 0.1953 (0.1953)\tPrec 91.797% (91.797%)\n",
      "Epoch: [55][100/196]\tTime 0.038 (0.081)\tData 0.001 (0.055)\tLoss 0.1795 (0.2234)\tPrec 93.359% (92.087%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.589 (4.589)\tLoss 0.5939 (0.5939)\tPrec 80.078% (80.078%)\n",
      " * Prec 80.850% \n",
      "best acc: 87.190000\n",
      "Epoch: [56][0/196]\tTime 5.678 (5.678)\tData 5.635 (5.635)\tLoss 0.3055 (0.3055)\tPrec 88.281% (88.281%)\n",
      "Epoch: [56][100/196]\tTime 0.030 (0.083)\tData 0.001 (0.057)\tLoss 0.2396 (0.2193)\tPrec 91.797% (92.280%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.689 (4.689)\tLoss 1.8788 (1.8788)\tPrec 60.938% (60.938%)\n",
      " * Prec 60.900% \n",
      "best acc: 87.190000\n",
      "Epoch: [57][0/196]\tTime 5.724 (5.724)\tData 5.698 (5.698)\tLoss 0.2524 (0.2524)\tPrec 91.797% (91.797%)\n",
      "Epoch: [57][100/196]\tTime 0.029 (0.084)\tData 0.001 (0.057)\tLoss 0.1984 (0.2270)\tPrec 93.359% (91.866%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.769 (4.769)\tLoss 0.6196 (0.6196)\tPrec 81.250% (81.250%)\n",
      " * Prec 81.350% \n",
      "best acc: 87.190000\n",
      "Epoch: [58][0/196]\tTime 5.819 (5.819)\tData 5.786 (5.786)\tLoss 0.2067 (0.2067)\tPrec 92.578% (92.578%)\n",
      "Epoch: [58][100/196]\tTime 0.028 (0.099)\tData 0.001 (0.058)\tLoss 0.2193 (0.2269)\tPrec 92.578% (91.890%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.869 (4.869)\tLoss 1.1204 (1.1204)\tPrec 64.062% (64.062%)\n",
      " * Prec 68.030% \n",
      "best acc: 87.190000\n",
      "Epoch: [59][0/196]\tTime 5.754 (5.754)\tData 5.719 (5.719)\tLoss 0.2211 (0.2211)\tPrec 93.750% (93.750%)\n",
      "Epoch: [59][100/196]\tTime 0.036 (0.104)\tData 0.001 (0.057)\tLoss 0.2694 (0.2196)\tPrec 88.281% (92.273%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.726 (4.726)\tLoss 0.5183 (0.5183)\tPrec 84.766% (84.766%)\n",
      " * Prec 84.350% \n",
      "best acc: 87.190000\n",
      "Epoch: [60][0/196]\tTime 5.808 (5.808)\tData 5.773 (5.773)\tLoss 0.2101 (0.2101)\tPrec 93.359% (93.359%)\n",
      "Epoch: [60][100/196]\tTime 0.069 (0.117)\tData 0.001 (0.058)\tLoss 0.2286 (0.2198)\tPrec 92.578% (92.338%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.781 (4.781)\tLoss 0.6729 (0.6729)\tPrec 82.422% (82.422%)\n",
      " * Prec 83.210% \n",
      "best acc: 87.190000\n",
      "Epoch: [61][0/196]\tTime 5.702 (5.702)\tData 5.658 (5.658)\tLoss 0.2332 (0.2332)\tPrec 92.578% (92.578%)\n",
      "Epoch: [61][100/196]\tTime 0.044 (0.122)\tData 0.001 (0.057)\tLoss 0.1797 (0.2205)\tPrec 93.359% (92.164%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.868 (4.868)\tLoss 0.9064 (0.9064)\tPrec 75.391% (75.391%)\n",
      " * Prec 78.900% \n",
      "best acc: 87.190000\n",
      "Epoch: [62][0/196]\tTime 5.812 (5.812)\tData 5.768 (5.768)\tLoss 0.1973 (0.1973)\tPrec 93.359% (93.359%)\n",
      "Epoch: [62][100/196]\tTime 0.029 (0.113)\tData 0.001 (0.058)\tLoss 0.1776 (0.2285)\tPrec 93.359% (91.963%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.762 (4.762)\tLoss 2.3145 (2.3145)\tPrec 39.062% (39.062%)\n",
      " * Prec 38.960% \n",
      "best acc: 87.190000\n",
      "Epoch: [63][0/196]\tTime 5.821 (5.821)\tData 5.777 (5.777)\tLoss 0.2777 (0.2777)\tPrec 89.844% (89.844%)\n",
      "Epoch: [63][100/196]\tTime 0.037 (0.114)\tData 0.001 (0.058)\tLoss 0.1524 (0.2175)\tPrec 94.922% (92.261%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.642 (4.642)\tLoss 0.7902 (0.7902)\tPrec 74.609% (74.609%)\n",
      " * Prec 75.080% \n",
      "best acc: 87.190000\n",
      "Epoch: [64][0/196]\tTime 5.627 (5.627)\tData 5.587 (5.587)\tLoss 0.1962 (0.1962)\tPrec 92.578% (92.578%)\n",
      "Epoch: [64][100/196]\tTime 0.059 (0.104)\tData 0.001 (0.056)\tLoss 0.1939 (0.2112)\tPrec 93.359% (92.574%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.733 (4.733)\tLoss 0.5429 (0.5429)\tPrec 84.375% (84.375%)\n",
      " * Prec 85.290% \n",
      "best acc: 87.190000\n",
      "Epoch: [65][0/196]\tTime 5.708 (5.708)\tData 5.681 (5.681)\tLoss 0.1477 (0.1477)\tPrec 95.703% (95.703%)\n",
      "Epoch: [65][100/196]\tTime 0.036 (0.099)\tData 0.001 (0.057)\tLoss 0.2387 (0.2252)\tPrec 92.188% (92.087%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.885 (4.885)\tLoss 0.5212 (0.5212)\tPrec 83.203% (83.203%)\n",
      " * Prec 84.420% \n",
      "best acc: 87.190000\n",
      "Epoch: [66][0/196]\tTime 5.765 (5.765)\tData 5.739 (5.739)\tLoss 0.2198 (0.2198)\tPrec 91.016% (91.016%)\n",
      "Epoch: [66][100/196]\tTime 0.037 (0.093)\tData 0.001 (0.058)\tLoss 0.2312 (0.2267)\tPrec 91.016% (92.079%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.698 (4.698)\tLoss 1.0331 (1.0331)\tPrec 69.531% (69.531%)\n",
      " * Prec 68.380% \n",
      "best acc: 87.190000\n",
      "Epoch: [67][0/196]\tTime 5.633 (5.633)\tData 5.611 (5.611)\tLoss 0.1973 (0.1973)\tPrec 92.188% (92.188%)\n",
      "Epoch: [67][100/196]\tTime 0.034 (0.084)\tData 0.001 (0.056)\tLoss 0.2107 (0.2209)\tPrec 91.797% (92.172%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.990 (4.990)\tLoss 1.2020 (1.2020)\tPrec 62.500% (62.500%)\n",
      " * Prec 65.640% \n",
      "best acc: 87.190000\n",
      "Epoch: [68][0/196]\tTime 5.609 (5.609)\tData 5.574 (5.574)\tLoss 0.2513 (0.2513)\tPrec 90.625% (90.625%)\n",
      "Epoch: [68][100/196]\tTime 0.065 (0.090)\tData 0.001 (0.056)\tLoss 0.2558 (0.2178)\tPrec 91.797% (92.377%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.887 (4.887)\tLoss 0.5470 (0.5470)\tPrec 83.203% (83.203%)\n",
      " * Prec 83.920% \n",
      "best acc: 87.190000\n",
      "Epoch: [69][0/196]\tTime 5.759 (5.759)\tData 5.726 (5.726)\tLoss 0.2273 (0.2273)\tPrec 90.234% (90.234%)\n",
      "Epoch: [69][100/196]\tTime 0.095 (0.117)\tData 0.001 (0.057)\tLoss 0.3088 (0.2256)\tPrec 88.281% (92.041%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.775 (4.775)\tLoss 0.4559 (0.4559)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.220% \n",
      "best acc: 87.190000\n",
      "Epoch: [70][0/196]\tTime 5.988 (5.988)\tData 5.962 (5.962)\tLoss 0.2490 (0.2490)\tPrec 93.359% (93.359%)\n",
      "Epoch: [70][100/196]\tTime 0.027 (0.085)\tData 0.001 (0.060)\tLoss 0.2042 (0.2207)\tPrec 91.406% (92.269%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.810 (4.810)\tLoss 0.5078 (0.5078)\tPrec 82.812% (82.812%)\n",
      " * Prec 83.270% \n",
      "best acc: 87.190000\n",
      "Epoch: [71][0/196]\tTime 5.589 (5.589)\tData 5.562 (5.562)\tLoss 0.2272 (0.2272)\tPrec 92.578% (92.578%)\n",
      "Epoch: [71][100/196]\tTime 0.025 (0.083)\tData 0.001 (0.056)\tLoss 0.2555 (0.2262)\tPrec 92.188% (92.091%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.736 (4.736)\tLoss 1.1115 (1.1115)\tPrec 74.609% (74.609%)\n",
      " * Prec 75.940% \n",
      "best acc: 87.190000\n",
      "Epoch: [72][0/196]\tTime 5.592 (5.592)\tData 5.571 (5.571)\tLoss 0.2729 (0.2729)\tPrec 89.844% (89.844%)\n",
      "Epoch: [72][100/196]\tTime 0.041 (0.083)\tData 0.001 (0.056)\tLoss 0.2076 (0.2243)\tPrec 92.188% (92.253%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.847 (4.847)\tLoss 0.6905 (0.6905)\tPrec 83.594% (83.594%)\n",
      " * Prec 84.000% \n",
      "best acc: 87.190000\n",
      "Epoch: [73][0/196]\tTime 5.410 (5.410)\tData 5.377 (5.377)\tLoss 0.2107 (0.2107)\tPrec 92.578% (92.578%)\n",
      "Epoch: [73][100/196]\tTime 0.028 (0.089)\tData 0.001 (0.054)\tLoss 0.2551 (0.2271)\tPrec 90.625% (91.866%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.682 (4.682)\tLoss 0.4529 (0.4529)\tPrec 84.375% (84.375%)\n",
      " * Prec 84.180% \n",
      "best acc: 87.190000\n",
      "Epoch: [74][0/196]\tTime 5.538 (5.538)\tData 5.488 (5.488)\tLoss 0.2476 (0.2476)\tPrec 91.406% (91.406%)\n",
      "Epoch: [74][100/196]\tTime 0.080 (0.112)\tData 0.001 (0.055)\tLoss 0.1882 (0.2201)\tPrec 93.359% (92.118%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.791 (4.791)\tLoss 0.4839 (0.4839)\tPrec 87.109% (87.109%)\n",
      " * Prec 86.060% \n",
      "best acc: 87.190000\n",
      "Epoch: [75][0/196]\tTime 5.674 (5.674)\tData 5.638 (5.638)\tLoss 0.2067 (0.2067)\tPrec 92.188% (92.188%)\n",
      "Epoch: [75][100/196]\tTime 0.053 (0.114)\tData 0.001 (0.057)\tLoss 0.1843 (0.2200)\tPrec 94.531% (92.358%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.799 (4.799)\tLoss 0.4509 (0.4509)\tPrec 83.594% (83.594%)\n",
      " * Prec 85.540% \n",
      "best acc: 87.190000\n",
      "Epoch: [76][0/196]\tTime 5.762 (5.762)\tData 5.725 (5.725)\tLoss 0.1966 (0.1966)\tPrec 91.797% (91.797%)\n",
      "Epoch: [76][100/196]\tTime 0.064 (0.127)\tData 0.001 (0.057)\tLoss 0.2063 (0.2246)\tPrec 90.625% (91.925%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.664 (4.664)\tLoss 0.4905 (0.4905)\tPrec 82.422% (82.422%)\n",
      " * Prec 83.450% \n",
      "best acc: 87.190000\n",
      "Epoch: [77][0/196]\tTime 5.898 (5.898)\tData 5.856 (5.856)\tLoss 0.2286 (0.2286)\tPrec 92.578% (92.578%)\n",
      "Epoch: [77][100/196]\tTime 0.032 (0.130)\tData 0.001 (0.059)\tLoss 0.1819 (0.2241)\tPrec 93.359% (92.029%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.928 (4.928)\tLoss 0.9656 (0.9656)\tPrec 76.562% (76.562%)\n",
      " * Prec 78.370% \n",
      "best acc: 87.190000\n",
      "Epoch: [78][0/196]\tTime 5.657 (5.657)\tData 5.613 (5.613)\tLoss 0.1950 (0.1950)\tPrec 94.531% (94.531%)\n",
      "Epoch: [78][100/196]\tTime 0.036 (0.109)\tData 0.001 (0.056)\tLoss 0.1584 (0.2223)\tPrec 93.750% (92.048%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.762 (4.762)\tLoss 0.6785 (0.6785)\tPrec 79.297% (79.297%)\n",
      " * Prec 81.270% \n",
      "best acc: 87.190000\n",
      "Epoch: [79][0/196]\tTime 5.762 (5.762)\tData 5.729 (5.729)\tLoss 0.1624 (0.1624)\tPrec 95.312% (95.312%)\n",
      "Epoch: [79][100/196]\tTime 0.035 (0.093)\tData 0.001 (0.057)\tLoss 0.2533 (0.2215)\tPrec 91.016% (92.304%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.927 (4.927)\tLoss 0.4814 (0.4814)\tPrec 82.812% (82.812%)\n",
      " * Prec 84.660% \n",
      "best acc: 87.190000\n",
      "Epoch: [80][0/196]\tTime 5.653 (5.653)\tData 5.626 (5.626)\tLoss 0.2640 (0.2640)\tPrec 90.625% (90.625%)\n",
      "Epoch: [80][100/196]\tTime 0.060 (0.103)\tData 0.001 (0.056)\tLoss 0.2156 (0.1934)\tPrec 92.578% (93.239%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.712 (4.712)\tLoss 0.4428 (0.4428)\tPrec 85.547% (85.547%)\n",
      " * Prec 86.590% \n",
      "best acc: 87.190000\n",
      "Epoch: [81][0/196]\tTime 5.717 (5.717)\tData 5.691 (5.691)\tLoss 0.1772 (0.1772)\tPrec 92.969% (92.969%)\n",
      "Epoch: [81][100/196]\tTime 0.029 (0.091)\tData 0.001 (0.057)\tLoss 0.1669 (0.1631)\tPrec 93.359% (94.462%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.720 (4.720)\tLoss 0.4200 (0.4200)\tPrec 85.156% (85.156%)\n",
      " * Prec 88.240% \n",
      "best acc: 88.240000\n",
      "Epoch: [82][0/196]\tTime 5.634 (5.634)\tData 5.611 (5.611)\tLoss 0.1623 (0.1623)\tPrec 94.141% (94.141%)\n",
      "Epoch: [82][100/196]\tTime 0.053 (0.088)\tData 0.001 (0.056)\tLoss 0.1217 (0.1631)\tPrec 96.484% (94.462%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.826 (4.826)\tLoss 0.5092 (0.5092)\tPrec 84.375% (84.375%)\n",
      " * Prec 88.390% \n",
      "best acc: 88.390000\n",
      "Epoch: [83][0/196]\tTime 5.538 (5.538)\tData 5.510 (5.510)\tLoss 0.1470 (0.1470)\tPrec 94.141% (94.141%)\n",
      "Epoch: [83][100/196]\tTime 0.074 (0.118)\tData 0.001 (0.055)\tLoss 0.1421 (0.1574)\tPrec 94.922% (94.570%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.792 (4.792)\tLoss 0.5145 (0.5145)\tPrec 83.203% (83.203%)\n",
      " * Prec 85.490% \n",
      "best acc: 88.390000\n",
      "Epoch: [84][0/196]\tTime 5.739 (5.739)\tData 5.709 (5.709)\tLoss 0.1568 (0.1568)\tPrec 94.922% (94.922%)\n",
      "Epoch: [84][100/196]\tTime 0.035 (0.087)\tData 0.001 (0.057)\tLoss 0.1613 (0.1563)\tPrec 94.141% (94.539%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.742 (4.742)\tLoss 0.6487 (0.6487)\tPrec 80.078% (80.078%)\n",
      " * Prec 81.070% \n",
      "best acc: 88.390000\n",
      "Epoch: [85][0/196]\tTime 5.755 (5.755)\tData 5.733 (5.733)\tLoss 0.1994 (0.1994)\tPrec 93.359% (93.359%)\n",
      "Epoch: [85][100/196]\tTime 0.027 (0.083)\tData 0.001 (0.057)\tLoss 0.1476 (0.1559)\tPrec 94.141% (94.531%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.617 (4.617)\tLoss 0.3841 (0.3841)\tPrec 85.547% (85.547%)\n",
      " * Prec 89.150% \n",
      "best acc: 89.150000\n",
      "Epoch: [86][0/196]\tTime 5.657 (5.657)\tData 5.635 (5.635)\tLoss 0.1870 (0.1870)\tPrec 94.531% (94.531%)\n",
      "Epoch: [86][100/196]\tTime 0.028 (0.084)\tData 0.001 (0.057)\tLoss 0.1514 (0.1555)\tPrec 94.141% (94.466%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.764 (4.764)\tLoss 0.4586 (0.4586)\tPrec 84.375% (84.375%)\n",
      " * Prec 87.500% \n",
      "best acc: 89.150000\n",
      "Epoch: [87][0/196]\tTime 5.649 (5.649)\tData 5.623 (5.623)\tLoss 0.1451 (0.1451)\tPrec 95.703% (95.703%)\n",
      "Epoch: [87][100/196]\tTime 0.027 (0.083)\tData 0.001 (0.056)\tLoss 0.1090 (0.1502)\tPrec 96.094% (94.756%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.733 (4.733)\tLoss 0.5332 (0.5332)\tPrec 83.203% (83.203%)\n",
      " * Prec 84.670% \n",
      "best acc: 89.150000\n",
      "Epoch: [88][0/196]\tTime 5.358 (5.358)\tData 5.319 (5.319)\tLoss 0.1268 (0.1268)\tPrec 96.094% (96.094%)\n",
      "Epoch: [88][100/196]\tTime 0.035 (0.094)\tData 0.001 (0.053)\tLoss 0.1872 (0.1479)\tPrec 92.969% (94.964%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.610 (4.610)\tLoss 0.5245 (0.5245)\tPrec 83.594% (83.594%)\n",
      " * Prec 85.730% \n",
      "best acc: 89.150000\n",
      "Epoch: [89][0/196]\tTime 5.722 (5.722)\tData 5.676 (5.676)\tLoss 0.1820 (0.1820)\tPrec 92.578% (92.578%)\n",
      "Epoch: [89][100/196]\tTime 0.055 (0.118)\tData 0.001 (0.057)\tLoss 0.2023 (0.1540)\tPrec 94.531% (94.582%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.724 (4.724)\tLoss 0.5648 (0.5648)\tPrec 82.812% (82.812%)\n",
      " * Prec 83.980% \n",
      "best acc: 89.150000\n",
      "Epoch: [90][0/196]\tTime 5.759 (5.759)\tData 5.727 (5.727)\tLoss 0.1447 (0.1447)\tPrec 93.359% (93.359%)\n",
      "Epoch: [90][100/196]\tTime 0.037 (0.109)\tData 0.001 (0.057)\tLoss 0.1463 (0.1549)\tPrec 94.922% (94.640%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.867 (4.867)\tLoss 0.6099 (0.6099)\tPrec 80.078% (80.078%)\n",
      " * Prec 82.090% \n",
      "best acc: 89.150000\n",
      "Epoch: [91][0/196]\tTime 5.704 (5.704)\tData 5.674 (5.674)\tLoss 0.1697 (0.1697)\tPrec 94.141% (94.141%)\n",
      "Epoch: [91][100/196]\tTime 0.041 (0.103)\tData 0.001 (0.057)\tLoss 0.1780 (0.1581)\tPrec 94.141% (94.392%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.693 (4.693)\tLoss 0.4488 (0.4488)\tPrec 83.594% (83.594%)\n",
      " * Prec 87.010% \n",
      "best acc: 89.150000\n",
      "Epoch: [92][0/196]\tTime 5.887 (5.887)\tData 5.860 (5.860)\tLoss 0.1490 (0.1490)\tPrec 93.750% (93.750%)\n",
      "Epoch: [92][100/196]\tTime 0.071 (0.117)\tData 0.001 (0.059)\tLoss 0.1838 (0.1480)\tPrec 92.969% (94.829%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.833 (4.833)\tLoss 0.5758 (0.5758)\tPrec 81.641% (81.641%)\n",
      " * Prec 84.870% \n",
      "best acc: 89.150000\n",
      "Epoch: [93][0/196]\tTime 5.593 (5.593)\tData 5.550 (5.550)\tLoss 0.0788 (0.0788)\tPrec 97.656% (97.656%)\n",
      "Epoch: [93][100/196]\tTime 0.057 (0.130)\tData 0.001 (0.056)\tLoss 0.0996 (0.1456)\tPrec 97.656% (94.852%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.741 (4.741)\tLoss 0.4067 (0.4067)\tPrec 85.938% (85.938%)\n",
      " * Prec 88.600% \n",
      "best acc: 89.150000\n",
      "Epoch: [94][0/196]\tTime 5.864 (5.864)\tData 5.826 (5.826)\tLoss 0.1405 (0.1405)\tPrec 94.531% (94.531%)\n",
      "Epoch: [94][100/196]\tTime 0.056 (0.106)\tData 0.001 (0.058)\tLoss 0.1101 (0.1456)\tPrec 96.875% (94.883%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.862 (4.862)\tLoss 0.3522 (0.3522)\tPrec 88.281% (88.281%)\n",
      " * Prec 89.530% \n",
      "best acc: 89.530000\n",
      "Epoch: [95][0/196]\tTime 5.602 (5.602)\tData 5.573 (5.573)\tLoss 0.1464 (0.1464)\tPrec 94.141% (94.141%)\n",
      "Epoch: [95][100/196]\tTime 0.055 (0.103)\tData 0.001 (0.056)\tLoss 0.2027 (0.1450)\tPrec 93.750% (94.964%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.694 (4.694)\tLoss 0.4866 (0.4866)\tPrec 83.594% (83.594%)\n",
      " * Prec 86.320% \n",
      "best acc: 89.530000\n",
      "Epoch: [96][0/196]\tTime 5.960 (5.960)\tData 5.934 (5.934)\tLoss 0.1234 (0.1234)\tPrec 96.484% (96.484%)\n",
      "Epoch: [96][100/196]\tTime 0.097 (0.126)\tData 0.001 (0.059)\tLoss 0.2008 (0.1449)\tPrec 93.750% (95.034%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.669 (4.669)\tLoss 0.4588 (0.4588)\tPrec 85.938% (85.938%)\n",
      " * Prec 87.810% \n",
      "best acc: 89.530000\n",
      "Epoch: [97][0/196]\tTime 5.756 (5.756)\tData 5.720 (5.720)\tLoss 0.1584 (0.1584)\tPrec 92.969% (92.969%)\n",
      "Epoch: [97][100/196]\tTime 0.042 (0.133)\tData 0.001 (0.057)\tLoss 0.1191 (0.1450)\tPrec 94.922% (94.868%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.726 (4.726)\tLoss 0.4741 (0.4741)\tPrec 84.766% (84.766%)\n",
      " * Prec 86.120% \n",
      "best acc: 89.530000\n",
      "Epoch: [98][0/196]\tTime 5.862 (5.862)\tData 5.818 (5.818)\tLoss 0.1252 (0.1252)\tPrec 95.703% (95.703%)\n",
      "Epoch: [98][100/196]\tTime 0.037 (0.115)\tData 0.001 (0.058)\tLoss 0.1497 (0.1456)\tPrec 95.312% (94.953%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.708 (4.708)\tLoss 0.8576 (0.8576)\tPrec 77.734% (77.734%)\n",
      " * Prec 82.100% \n",
      "best acc: 89.530000\n",
      "Epoch: [99][0/196]\tTime 5.823 (5.823)\tData 5.779 (5.779)\tLoss 0.1516 (0.1516)\tPrec 93.750% (93.750%)\n",
      "Epoch: [99][100/196]\tTime 0.034 (0.114)\tData 0.001 (0.058)\tLoss 0.1433 (0.1473)\tPrec 95.312% (94.814%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.679 (4.679)\tLoss 0.8250 (0.8250)\tPrec 73.438% (73.438%)\n",
      " * Prec 76.120% \n",
      "best acc: 89.530000\n",
      "Epoch: [100][0/196]\tTime 5.858 (5.858)\tData 5.826 (5.826)\tLoss 0.0815 (0.0815)\tPrec 96.875% (96.875%)\n",
      "Epoch: [100][100/196]\tTime 0.035 (0.101)\tData 0.001 (0.058)\tLoss 0.1120 (0.1459)\tPrec 96.875% (94.999%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.839 (4.839)\tLoss 0.3985 (0.3985)\tPrec 86.719% (86.719%)\n",
      " * Prec 88.680% \n",
      "best acc: 89.530000\n",
      "Epoch: [101][0/196]\tTime 5.724 (5.724)\tData 5.700 (5.700)\tLoss 0.1301 (0.1301)\tPrec 95.703% (95.703%)\n",
      "Epoch: [101][100/196]\tTime 0.039 (0.093)\tData 0.001 (0.057)\tLoss 0.1783 (0.1495)\tPrec 93.359% (94.779%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.901 (4.901)\tLoss 0.3610 (0.3610)\tPrec 87.109% (87.109%)\n",
      " * Prec 89.160% \n",
      "best acc: 89.530000\n",
      "Epoch: [102][0/196]\tTime 5.798 (5.798)\tData 5.774 (5.774)\tLoss 0.1700 (0.1700)\tPrec 93.359% (93.359%)\n",
      "Epoch: [102][100/196]\tTime 0.071 (0.122)\tData 0.001 (0.058)\tLoss 0.1540 (0.1425)\tPrec 94.922% (95.034%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.721 (4.721)\tLoss 0.5853 (0.5853)\tPrec 82.422% (82.422%)\n",
      " * Prec 83.560% \n",
      "best acc: 89.530000\n",
      "Epoch: [103][0/196]\tTime 5.697 (5.697)\tData 5.663 (5.663)\tLoss 0.1165 (0.1165)\tPrec 95.312% (95.312%)\n",
      "Epoch: [103][100/196]\tTime 0.061 (0.110)\tData 0.001 (0.057)\tLoss 0.1016 (0.1465)\tPrec 97.656% (94.825%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.831 (4.831)\tLoss 0.5388 (0.5388)\tPrec 80.469% (80.469%)\n",
      " * Prec 84.090% \n",
      "best acc: 89.530000\n",
      "Epoch: [104][0/196]\tTime 5.684 (5.684)\tData 5.649 (5.649)\tLoss 0.1868 (0.1868)\tPrec 94.141% (94.141%)\n",
      "Epoch: [104][100/196]\tTime 0.055 (0.111)\tData 0.001 (0.057)\tLoss 0.1689 (0.1379)\tPrec 93.750% (95.224%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.753 (4.753)\tLoss 0.9283 (0.9283)\tPrec 76.562% (76.562%)\n",
      " * Prec 79.950% \n",
      "best acc: 89.530000\n",
      "Epoch: [105][0/196]\tTime 5.825 (5.825)\tData 5.796 (5.796)\tLoss 0.1478 (0.1478)\tPrec 93.359% (93.359%)\n",
      "Epoch: [105][100/196]\tTime 0.087 (0.127)\tData 0.001 (0.058)\tLoss 0.1347 (0.1428)\tPrec 93.750% (94.790%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.702 (4.702)\tLoss 0.4517 (0.4517)\tPrec 85.938% (85.938%)\n",
      " * Prec 87.240% \n",
      "best acc: 89.530000\n",
      "Epoch: [106][0/196]\tTime 5.952 (5.952)\tData 5.914 (5.914)\tLoss 0.0888 (0.0888)\tPrec 96.875% (96.875%)\n",
      "Epoch: [106][100/196]\tTime 0.051 (0.134)\tData 0.001 (0.059)\tLoss 0.1385 (0.1425)\tPrec 96.094% (95.050%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.732 (4.732)\tLoss 0.7010 (0.7010)\tPrec 77.344% (77.344%)\n",
      " * Prec 80.720% \n",
      "best acc: 89.530000\n",
      "Epoch: [107][0/196]\tTime 5.613 (5.613)\tData 5.588 (5.588)\tLoss 0.1422 (0.1422)\tPrec 94.922% (94.922%)\n",
      "Epoch: [107][100/196]\tTime 0.059 (0.112)\tData 0.001 (0.056)\tLoss 0.1248 (0.1383)\tPrec 94.922% (95.150%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.845 (4.845)\tLoss 0.4428 (0.4428)\tPrec 84.375% (84.375%)\n",
      " * Prec 87.080% \n",
      "best acc: 89.530000\n",
      "Epoch: [108][0/196]\tTime 6.016 (6.016)\tData 5.991 (5.991)\tLoss 0.1338 (0.1338)\tPrec 95.312% (95.312%)\n",
      "Epoch: [108][100/196]\tTime 0.096 (0.130)\tData 0.001 (0.060)\tLoss 0.1626 (0.1446)\tPrec 94.141% (94.995%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.739 (4.739)\tLoss 0.5566 (0.5566)\tPrec 85.938% (85.938%)\n",
      " * Prec 86.720% \n",
      "best acc: 89.530000\n",
      "Epoch: [109][0/196]\tTime 5.871 (5.871)\tData 5.827 (5.827)\tLoss 0.1404 (0.1404)\tPrec 96.094% (96.094%)\n",
      "Epoch: [109][100/196]\tTime 0.060 (0.146)\tData 0.001 (0.058)\tLoss 0.1282 (0.1421)\tPrec 95.312% (94.926%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.719 (4.719)\tLoss 0.4695 (0.4695)\tPrec 84.375% (84.375%)\n",
      " * Prec 86.680% \n",
      "best acc: 89.530000\n",
      "Epoch: [110][0/196]\tTime 5.792 (5.792)\tData 5.750 (5.750)\tLoss 0.2447 (0.2447)\tPrec 90.234% (90.234%)\n",
      "Epoch: [110][100/196]\tTime 0.051 (0.115)\tData 0.001 (0.058)\tLoss 0.1726 (0.1411)\tPrec 94.531% (94.984%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.916 (4.916)\tLoss 0.4364 (0.4364)\tPrec 86.328% (86.328%)\n",
      " * Prec 88.150% \n",
      "best acc: 89.530000\n",
      "Epoch: [111][0/196]\tTime 5.706 (5.706)\tData 5.676 (5.676)\tLoss 0.1583 (0.1583)\tPrec 94.531% (94.531%)\n",
      "Epoch: [111][100/196]\tTime 0.093 (0.117)\tData 0.001 (0.057)\tLoss 0.1219 (0.1413)\tPrec 96.094% (94.968%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.702 (4.702)\tLoss 0.4085 (0.4085)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.900% \n",
      "best acc: 89.530000\n",
      "Epoch: [112][0/196]\tTime 5.846 (5.846)\tData 5.805 (5.805)\tLoss 0.1661 (0.1661)\tPrec 93.750% (93.750%)\n",
      "Epoch: [112][100/196]\tTime 0.078 (0.135)\tData 0.001 (0.058)\tLoss 0.1111 (0.1380)\tPrec 94.922% (95.108%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.853 (4.853)\tLoss 0.8795 (0.8795)\tPrec 78.906% (78.906%)\n",
      " * Prec 81.500% \n",
      "best acc: 89.530000\n",
      "Epoch: [113][0/196]\tTime 5.739 (5.739)\tData 5.705 (5.705)\tLoss 0.2135 (0.2135)\tPrec 93.750% (93.750%)\n",
      "Epoch: [113][100/196]\tTime 0.037 (0.103)\tData 0.001 (0.057)\tLoss 0.1774 (0.1406)\tPrec 93.750% (94.945%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.913 (4.913)\tLoss 0.5925 (0.5925)\tPrec 81.641% (81.641%)\n",
      " * Prec 83.360% \n",
      "best acc: 89.530000\n",
      "Epoch: [114][0/196]\tTime 5.704 (5.704)\tData 5.677 (5.677)\tLoss 0.1049 (0.1049)\tPrec 96.094% (96.094%)\n",
      "Epoch: [114][100/196]\tTime 0.033 (0.096)\tData 0.001 (0.057)\tLoss 0.1175 (0.1443)\tPrec 96.484% (94.868%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.772 (4.772)\tLoss 0.9097 (0.9097)\tPrec 76.172% (76.172%)\n",
      " * Prec 81.160% \n",
      "best acc: 89.530000\n",
      "Epoch: [115][0/196]\tTime 5.669 (5.669)\tData 5.631 (5.631)\tLoss 0.1159 (0.1159)\tPrec 96.484% (96.484%)\n",
      "Epoch: [115][100/196]\tTime 0.038 (0.093)\tData 0.001 (0.057)\tLoss 0.1244 (0.1428)\tPrec 96.484% (94.999%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.826 (4.826)\tLoss 0.4687 (0.4687)\tPrec 85.547% (85.547%)\n",
      " * Prec 87.370% \n",
      "best acc: 89.530000\n",
      "Epoch: [116][0/196]\tTime 5.724 (5.724)\tData 5.699 (5.699)\tLoss 0.1283 (0.1283)\tPrec 94.922% (94.922%)\n",
      "Epoch: [116][100/196]\tTime 0.035 (0.093)\tData 0.001 (0.057)\tLoss 0.1444 (0.1416)\tPrec 94.922% (94.964%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.822 (4.822)\tLoss 0.5599 (0.5599)\tPrec 84.766% (84.766%)\n",
      " * Prec 87.590% \n",
      "best acc: 89.530000\n",
      "Epoch: [117][0/196]\tTime 5.715 (5.715)\tData 5.681 (5.681)\tLoss 0.1095 (0.1095)\tPrec 96.875% (96.875%)\n",
      "Epoch: [117][100/196]\tTime 0.094 (0.128)\tData 0.001 (0.057)\tLoss 0.1461 (0.1395)\tPrec 94.922% (95.003%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.736 (4.736)\tLoss 0.4899 (0.4899)\tPrec 85.547% (85.547%)\n",
      " * Prec 86.060% \n",
      "best acc: 89.530000\n",
      "Epoch: [118][0/196]\tTime 5.747 (5.747)\tData 5.713 (5.713)\tLoss 0.1469 (0.1469)\tPrec 95.312% (95.312%)\n",
      "Epoch: [118][100/196]\tTime 0.053 (0.115)\tData 0.001 (0.057)\tLoss 0.1503 (0.1390)\tPrec 95.703% (95.100%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.872 (4.872)\tLoss 0.6263 (0.6263)\tPrec 83.984% (83.984%)\n",
      " * Prec 85.960% \n",
      "best acc: 89.530000\n",
      "Epoch: [119][0/196]\tTime 5.685 (5.685)\tData 5.654 (5.654)\tLoss 0.1860 (0.1860)\tPrec 91.406% (91.406%)\n",
      "Epoch: [119][100/196]\tTime 0.052 (0.109)\tData 0.001 (0.057)\tLoss 0.1790 (0.1420)\tPrec 91.406% (94.887%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.805 (4.805)\tLoss 0.8488 (0.8488)\tPrec 79.297% (79.297%)\n",
      " * Prec 82.550% \n",
      "best acc: 89.530000\n",
      "Epoch: [120][0/196]\tTime 5.674 (5.674)\tData 5.644 (5.644)\tLoss 0.1239 (0.1239)\tPrec 95.312% (95.312%)\n",
      "Epoch: [120][100/196]\tTime 0.093 (0.127)\tData 0.001 (0.057)\tLoss 0.1250 (0.1345)\tPrec 96.094% (95.278%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.733 (4.733)\tLoss 0.3968 (0.3968)\tPrec 88.281% (88.281%)\n",
      " * Prec 89.470% \n",
      "best acc: 89.530000\n",
      "Epoch: [121][0/196]\tTime 5.700 (5.700)\tData 5.669 (5.669)\tLoss 0.1213 (0.1213)\tPrec 94.922% (94.922%)\n",
      "Epoch: [121][100/196]\tTime 0.058 (0.122)\tData 0.001 (0.057)\tLoss 0.1402 (0.1334)\tPrec 94.531% (95.204%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.872 (4.872)\tLoss 0.7678 (0.7678)\tPrec 80.078% (80.078%)\n",
      " * Prec 83.610% \n",
      "best acc: 89.530000\n",
      "Epoch: [122][0/196]\tTime 5.771 (5.771)\tData 5.748 (5.748)\tLoss 0.1116 (0.1116)\tPrec 97.266% (97.266%)\n",
      "Epoch: [122][100/196]\tTime 0.054 (0.106)\tData 0.001 (0.058)\tLoss 0.1698 (0.1311)\tPrec 93.359% (95.305%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.706 (4.706)\tLoss 1.6027 (1.6027)\tPrec 68.359% (68.359%)\n",
      " * Prec 69.330% \n",
      "best acc: 89.530000\n",
      "Epoch: [123][0/196]\tTime 5.636 (5.636)\tData 5.609 (5.609)\tLoss 0.1383 (0.1383)\tPrec 95.312% (95.312%)\n",
      "Epoch: [123][100/196]\tTime 0.053 (0.084)\tData 0.001 (0.056)\tLoss 0.1146 (0.1314)\tPrec 96.094% (95.301%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.717 (4.717)\tLoss 0.6562 (0.6562)\tPrec 83.984% (83.984%)\n",
      " * Prec 86.900% \n",
      "best acc: 89.530000\n",
      "Epoch: [124][0/196]\tTime 5.683 (5.683)\tData 5.662 (5.662)\tLoss 0.1328 (0.1328)\tPrec 95.703% (95.703%)\n",
      "Epoch: [124][100/196]\tTime 0.029 (0.082)\tData 0.001 (0.057)\tLoss 0.1376 (0.1355)\tPrec 94.922% (95.115%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.785 (4.785)\tLoss 0.4928 (0.4928)\tPrec 83.984% (83.984%)\n",
      " * Prec 85.920% \n",
      "best acc: 89.530000\n",
      "Epoch: [125][0/196]\tTime 5.708 (5.708)\tData 5.686 (5.686)\tLoss 0.1566 (0.1566)\tPrec 94.922% (94.922%)\n",
      "Epoch: [125][100/196]\tTime 0.057 (0.088)\tData 0.001 (0.057)\tLoss 0.1508 (0.1356)\tPrec 94.141% (95.193%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.910 (4.910)\tLoss 0.5241 (0.5241)\tPrec 84.766% (84.766%)\n",
      " * Prec 85.840% \n",
      "best acc: 89.530000\n",
      "Epoch: [126][0/196]\tTime 5.585 (5.585)\tData 5.562 (5.562)\tLoss 0.0935 (0.0935)\tPrec 97.656% (97.656%)\n",
      "Epoch: [126][100/196]\tTime 0.055 (0.105)\tData 0.001 (0.056)\tLoss 0.1623 (0.1337)\tPrec 94.922% (95.251%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.817 (4.817)\tLoss 0.5334 (0.5334)\tPrec 83.203% (83.203%)\n",
      " * Prec 85.440% \n",
      "best acc: 89.530000\n",
      "Epoch: [127][0/196]\tTime 5.764 (5.764)\tData 5.725 (5.725)\tLoss 0.1503 (0.1503)\tPrec 94.141% (94.141%)\n",
      "Epoch: [127][100/196]\tTime 0.029 (0.100)\tData 0.001 (0.057)\tLoss 0.1482 (0.1336)\tPrec 94.531% (95.227%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.837 (4.837)\tLoss 0.9334 (0.9334)\tPrec 68.750% (68.750%)\n",
      " * Prec 72.900% \n",
      "best acc: 89.530000\n",
      "Epoch: [128][0/196]\tTime 5.821 (5.821)\tData 5.787 (5.787)\tLoss 0.1707 (0.1707)\tPrec 91.016% (91.016%)\n",
      "Epoch: [128][100/196]\tTime 0.029 (0.090)\tData 0.001 (0.058)\tLoss 0.1313 (0.1315)\tPrec 95.703% (95.394%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.933 (4.933)\tLoss 0.8606 (0.8606)\tPrec 79.688% (79.688%)\n",
      " * Prec 82.420% \n",
      "best acc: 89.530000\n",
      "Epoch: [129][0/196]\tTime 5.540 (5.540)\tData 5.507 (5.507)\tLoss 0.1464 (0.1464)\tPrec 95.312% (95.312%)\n",
      "Epoch: [129][100/196]\tTime 0.027 (0.090)\tData 0.001 (0.055)\tLoss 0.1190 (0.1320)\tPrec 95.703% (95.382%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.721 (4.721)\tLoss 0.6184 (0.6184)\tPrec 85.156% (85.156%)\n",
      " * Prec 87.310% \n",
      "best acc: 89.530000\n",
      "Epoch: [130][0/196]\tTime 5.542 (5.542)\tData 5.495 (5.495)\tLoss 0.2577 (0.2577)\tPrec 91.797% (91.797%)\n",
      "Epoch: [130][100/196]\tTime 0.028 (0.126)\tData 0.001 (0.055)\tLoss 0.1307 (0.1335)\tPrec 95.312% (95.239%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.667 (4.667)\tLoss 0.4189 (0.4189)\tPrec 87.500% (87.500%)\n",
      " * Prec 89.320% \n",
      "best acc: 89.530000\n",
      "Epoch: [131][0/196]\tTime 5.783 (5.783)\tData 5.736 (5.736)\tLoss 0.1294 (0.1294)\tPrec 95.312% (95.312%)\n",
      "Epoch: [131][100/196]\tTime 0.061 (0.122)\tData 0.001 (0.057)\tLoss 0.1320 (0.1327)\tPrec 94.922% (95.374%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.730 (4.730)\tLoss 0.4349 (0.4349)\tPrec 85.938% (85.938%)\n",
      " * Prec 87.850% \n",
      "best acc: 89.530000\n",
      "Epoch: [132][0/196]\tTime 5.862 (5.862)\tData 5.827 (5.827)\tLoss 0.1157 (0.1157)\tPrec 95.703% (95.703%)\n",
      "Epoch: [132][100/196]\tTime 0.057 (0.116)\tData 0.001 (0.058)\tLoss 0.1901 (0.1308)\tPrec 92.578% (95.405%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.832 (4.832)\tLoss 0.5981 (0.5981)\tPrec 84.375% (84.375%)\n",
      " * Prec 87.390% \n",
      "best acc: 89.530000\n",
      "Epoch: [133][0/196]\tTime 5.743 (5.743)\tData 5.708 (5.708)\tLoss 0.1523 (0.1523)\tPrec 95.312% (95.312%)\n",
      "Epoch: [133][100/196]\tTime 0.091 (0.133)\tData 0.001 (0.057)\tLoss 0.1302 (0.1352)\tPrec 94.922% (95.258%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.753 (4.753)\tLoss 1.3659 (1.3659)\tPrec 71.875% (71.875%)\n",
      " * Prec 71.830% \n",
      "best acc: 89.530000\n",
      "Epoch: [134][0/196]\tTime 5.844 (5.844)\tData 5.793 (5.793)\tLoss 0.1615 (0.1615)\tPrec 94.141% (94.141%)\n",
      "Epoch: [134][100/196]\tTime 0.040 (0.143)\tData 0.001 (0.058)\tLoss 0.1897 (0.1360)\tPrec 92.578% (95.204%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.747 (4.747)\tLoss 0.6148 (0.6148)\tPrec 85.156% (85.156%)\n",
      " * Prec 87.190% \n",
      "best acc: 89.530000\n",
      "Epoch: [135][0/196]\tTime 5.815 (5.815)\tData 5.764 (5.764)\tLoss 0.1406 (0.1406)\tPrec 96.094% (96.094%)\n",
      "Epoch: [135][100/196]\tTime 0.035 (0.127)\tData 0.001 (0.058)\tLoss 0.1081 (0.1375)\tPrec 96.484% (95.022%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.672 (4.672)\tLoss 0.8254 (0.8254)\tPrec 72.656% (72.656%)\n",
      " * Prec 76.390% \n",
      "best acc: 89.530000\n",
      "Epoch: [136][0/196]\tTime 5.743 (5.743)\tData 5.707 (5.707)\tLoss 0.1162 (0.1162)\tPrec 95.703% (95.703%)\n",
      "Epoch: [136][100/196]\tTime 0.037 (0.113)\tData 0.001 (0.057)\tLoss 0.0925 (0.1313)\tPrec 96.484% (95.316%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.915 (4.915)\tLoss 0.7740 (0.7740)\tPrec 80.078% (80.078%)\n",
      " * Prec 83.310% \n",
      "best acc: 89.530000\n",
      "Epoch: [137][0/196]\tTime 5.785 (5.785)\tData 5.757 (5.757)\tLoss 0.1710 (0.1710)\tPrec 92.969% (92.969%)\n",
      "Epoch: [137][100/196]\tTime 0.033 (0.100)\tData 0.001 (0.058)\tLoss 0.0982 (0.1333)\tPrec 97.656% (95.328%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.712 (4.712)\tLoss 0.4139 (0.4139)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.550% \n",
      "best acc: 89.530000\n",
      "Epoch: [138][0/196]\tTime 5.672 (5.672)\tData 5.648 (5.648)\tLoss 0.1197 (0.1197)\tPrec 95.703% (95.703%)\n",
      "Epoch: [138][100/196]\tTime 0.090 (0.104)\tData 0.001 (0.057)\tLoss 0.1791 (0.1293)\tPrec 94.531% (95.309%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.901 (4.901)\tLoss 0.4493 (0.4493)\tPrec 85.156% (85.156%)\n",
      " * Prec 88.630% \n",
      "best acc: 89.530000\n",
      "Epoch: [139][0/196]\tTime 5.580 (5.580)\tData 5.544 (5.544)\tLoss 0.1782 (0.1782)\tPrec 90.625% (90.625%)\n",
      "Epoch: [139][100/196]\tTime 0.096 (0.132)\tData 0.001 (0.056)\tLoss 0.1297 (0.1282)\tPrec 94.141% (95.548%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.773 (4.773)\tLoss 0.7713 (0.7713)\tPrec 82.031% (82.031%)\n",
      " * Prec 84.210% \n",
      "best acc: 89.530000\n",
      "Epoch: [140][0/196]\tTime 5.733 (5.733)\tData 5.709 (5.709)\tLoss 0.1417 (0.1417)\tPrec 94.922% (94.922%)\n",
      "Epoch: [140][100/196]\tTime 0.057 (0.099)\tData 0.001 (0.057)\tLoss 0.1501 (0.1339)\tPrec 94.141% (95.243%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.928 (4.928)\tLoss 1.4179 (1.4179)\tPrec 70.703% (70.703%)\n",
      " * Prec 71.450% \n",
      "best acc: 89.530000\n",
      "Epoch: [141][0/196]\tTime 5.614 (5.614)\tData 5.588 (5.588)\tLoss 0.1467 (0.1467)\tPrec 93.750% (93.750%)\n",
      "Epoch: [141][100/196]\tTime 0.057 (0.103)\tData 0.001 (0.056)\tLoss 0.1424 (0.1269)\tPrec 94.922% (95.340%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.756 (4.756)\tLoss 0.6450 (0.6450)\tPrec 84.766% (84.766%)\n",
      " * Prec 86.370% \n",
      "best acc: 89.530000\n",
      "Epoch: [142][0/196]\tTime 5.670 (5.670)\tData 5.644 (5.644)\tLoss 0.1251 (0.1251)\tPrec 95.703% (95.703%)\n",
      "Epoch: [142][100/196]\tTime 0.091 (0.113)\tData 0.001 (0.057)\tLoss 0.1209 (0.1337)\tPrec 94.141% (95.208%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.754 (4.754)\tLoss 0.4777 (0.4777)\tPrec 83.203% (83.203%)\n",
      " * Prec 86.440% \n",
      "best acc: 89.530000\n",
      "Epoch: [143][0/196]\tTime 5.785 (5.785)\tData 5.753 (5.753)\tLoss 0.1701 (0.1701)\tPrec 94.922% (94.922%)\n",
      "Epoch: [143][100/196]\tTime 0.056 (0.132)\tData 0.001 (0.058)\tLoss 0.0995 (0.1285)\tPrec 98.047% (95.483%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.649 (4.649)\tLoss 0.6355 (0.6355)\tPrec 84.766% (84.766%)\n",
      " * Prec 86.380% \n",
      "best acc: 89.530000\n",
      "Epoch: [144][0/196]\tTime 5.596 (5.596)\tData 5.574 (5.574)\tLoss 0.1173 (0.1173)\tPrec 97.656% (97.656%)\n",
      "Epoch: [144][100/196]\tTime 0.080 (0.094)\tData 0.001 (0.056)\tLoss 0.0903 (0.1323)\tPrec 96.875% (95.316%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.871 (4.871)\tLoss 0.7872 (0.7872)\tPrec 81.641% (81.641%)\n",
      " * Prec 84.370% \n",
      "best acc: 89.530000\n",
      "Epoch: [145][0/196]\tTime 5.772 (5.772)\tData 5.745 (5.745)\tLoss 0.1221 (0.1221)\tPrec 95.703% (95.703%)\n",
      "Epoch: [145][100/196]\tTime 0.035 (0.083)\tData 0.001 (0.058)\tLoss 0.1938 (0.1240)\tPrec 94.531% (95.649%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.580 (4.580)\tLoss 0.4297 (0.4297)\tPrec 86.328% (86.328%)\n",
      " * Prec 88.300% \n",
      "best acc: 89.530000\n",
      "Epoch: [146][0/196]\tTime 5.571 (5.571)\tData 5.541 (5.541)\tLoss 0.1058 (0.1058)\tPrec 94.141% (94.141%)\n",
      "Epoch: [146][100/196]\tTime 0.031 (0.082)\tData 0.001 (0.056)\tLoss 0.0708 (0.1311)\tPrec 97.266% (95.247%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.735 (4.735)\tLoss 0.4060 (0.4060)\tPrec 87.109% (87.109%)\n",
      " * Prec 89.340% \n",
      "best acc: 89.530000\n",
      "Epoch: [147][0/196]\tTime 5.704 (5.704)\tData 5.684 (5.684)\tLoss 0.2024 (0.2024)\tPrec 92.969% (92.969%)\n",
      "Epoch: [147][100/196]\tTime 0.030 (0.084)\tData 0.001 (0.057)\tLoss 0.1235 (0.1336)\tPrec 94.141% (95.220%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.881 (4.881)\tLoss 0.5159 (0.5159)\tPrec 85.547% (85.547%)\n",
      " * Prec 88.720% \n",
      "best acc: 89.530000\n",
      "Epoch: [148][0/196]\tTime 5.750 (5.750)\tData 5.719 (5.719)\tLoss 0.1383 (0.1383)\tPrec 94.922% (94.922%)\n",
      "Epoch: [148][100/196]\tTime 0.028 (0.091)\tData 0.001 (0.057)\tLoss 0.1406 (0.1311)\tPrec 95.312% (95.401%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.876 (4.876)\tLoss 0.6036 (0.6036)\tPrec 81.641% (81.641%)\n",
      " * Prec 82.860% \n",
      "best acc: 89.530000\n",
      "Epoch: [149][0/196]\tTime 5.716 (5.716)\tData 5.680 (5.680)\tLoss 0.1670 (0.1670)\tPrec 92.578% (92.578%)\n",
      "Epoch: [149][100/196]\tTime 0.073 (0.115)\tData 0.001 (0.057)\tLoss 0.1172 (0.1300)\tPrec 96.484% (95.340%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.763 (4.763)\tLoss 0.4348 (0.4348)\tPrec 87.109% (87.109%)\n",
      " * Prec 89.940% \n",
      "best acc: 89.940000\n",
      "Epoch: [150][0/196]\tTime 5.916 (5.916)\tData 5.882 (5.882)\tLoss 0.1060 (0.1060)\tPrec 96.484% (96.484%)\n",
      "Epoch: [150][100/196]\tTime 0.058 (0.129)\tData 0.001 (0.059)\tLoss 0.1210 (0.1316)\tPrec 95.312% (95.166%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.662 (4.662)\tLoss 0.7729 (0.7729)\tPrec 81.250% (81.250%)\n",
      " * Prec 83.800% \n",
      "best acc: 89.940000\n",
      "Epoch: [151][0/196]\tTime 5.755 (5.755)\tData 5.710 (5.710)\tLoss 0.0976 (0.0976)\tPrec 95.312% (95.312%)\n",
      "Epoch: [151][100/196]\tTime 0.028 (0.134)\tData 0.001 (0.057)\tLoss 0.1469 (0.1323)\tPrec 95.703% (95.251%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.612 (4.612)\tLoss 0.5514 (0.5514)\tPrec 87.109% (87.109%)\n",
      " * Prec 88.320% \n",
      "best acc: 89.940000\n",
      "Epoch: [152][0/196]\tTime 5.292 (5.292)\tData 5.258 (5.258)\tLoss 0.0713 (0.0713)\tPrec 97.266% (97.266%)\n",
      "Epoch: [152][100/196]\tTime 0.039 (0.112)\tData 0.001 (0.053)\tLoss 0.1281 (0.1250)\tPrec 94.531% (95.548%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.498 (4.498)\tLoss 0.7615 (0.7615)\tPrec 82.422% (82.422%)\n",
      " * Prec 84.920% \n",
      "best acc: 89.940000\n",
      "Epoch: [153][0/196]\tTime 5.566 (5.566)\tData 5.529 (5.529)\tLoss 0.1987 (0.1987)\tPrec 92.969% (92.969%)\n",
      "Epoch: [153][100/196]\tTime 0.034 (0.098)\tData 0.001 (0.055)\tLoss 0.1305 (0.1303)\tPrec 96.094% (95.355%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.408 (4.408)\tLoss 0.7540 (0.7540)\tPrec 80.859% (80.859%)\n",
      " * Prec 84.750% \n",
      "best acc: 89.940000\n",
      "Epoch: [154][0/196]\tTime 5.561 (5.561)\tData 5.537 (5.537)\tLoss 0.0885 (0.0885)\tPrec 97.656% (97.656%)\n",
      "Epoch: [154][100/196]\tTime 0.065 (0.093)\tData 0.001 (0.055)\tLoss 0.1305 (0.1298)\tPrec 95.312% (95.548%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.646 (4.646)\tLoss 0.6350 (0.6350)\tPrec 83.594% (83.594%)\n",
      " * Prec 87.080% \n",
      "best acc: 89.940000\n",
      "Epoch: [155][0/196]\tTime 5.293 (5.293)\tData 5.269 (5.269)\tLoss 0.1744 (0.1744)\tPrec 92.969% (92.969%)\n",
      "Epoch: [155][100/196]\tTime 0.033 (0.091)\tData 0.001 (0.053)\tLoss 0.1591 (0.1309)\tPrec 94.531% (95.405%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.791 (4.791)\tLoss 0.3843 (0.3843)\tPrec 86.328% (86.328%)\n",
      " * Prec 89.540% \n",
      "best acc: 89.940000\n",
      "Epoch: [156][0/196]\tTime 5.116 (5.116)\tData 5.089 (5.089)\tLoss 0.1095 (0.1095)\tPrec 96.875% (96.875%)\n",
      "Epoch: [156][100/196]\tTime 0.039 (0.087)\tData 0.001 (0.051)\tLoss 0.1162 (0.1322)\tPrec 96.875% (95.463%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.520 (4.520)\tLoss 0.7314 (0.7314)\tPrec 83.203% (83.203%)\n",
      " * Prec 84.680% \n",
      "best acc: 89.940000\n",
      "Epoch: [157][0/196]\tTime 5.216 (5.216)\tData 5.190 (5.190)\tLoss 0.1577 (0.1577)\tPrec 95.703% (95.703%)\n",
      "Epoch: [157][100/196]\tTime 0.069 (0.099)\tData 0.001 (0.052)\tLoss 0.1416 (0.1315)\tPrec 93.359% (95.247%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.485 (4.485)\tLoss 0.4143 (0.4143)\tPrec 87.500% (87.500%)\n",
      " * Prec 89.120% \n",
      "best acc: 89.940000\n",
      "Epoch: [158][0/196]\tTime 5.304 (5.304)\tData 5.268 (5.268)\tLoss 0.1132 (0.1132)\tPrec 96.094% (96.094%)\n",
      "Epoch: [158][100/196]\tTime 0.035 (0.124)\tData 0.001 (0.053)\tLoss 0.1194 (0.1306)\tPrec 95.703% (95.309%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.475 (4.475)\tLoss 0.4076 (0.4076)\tPrec 87.500% (87.500%)\n",
      " * Prec 88.940% \n",
      "best acc: 89.940000\n",
      "Epoch: [159][0/196]\tTime 5.427 (5.427)\tData 5.397 (5.397)\tLoss 0.0962 (0.0962)\tPrec 97.656% (97.656%)\n",
      "Epoch: [159][100/196]\tTime 0.032 (0.093)\tData 0.001 (0.054)\tLoss 0.1208 (0.1329)\tPrec 94.531% (95.243%)\n",
      "Validation starts\n",
      "Test: [0/40]\tTime 4.370 (4.370)\tLoss 0.6912 (0.6912)\tPrec 82.422% (82.422%)\n",
      " * Prec 85.270% \n",
      "best acc: 89.940000\n"
     ]
    }
   ],
   "source": [
    "## Start finetuning (training here), and see how much you can recover your accuracy ##\n",
    "## You can change hyper parameters such as epochs or lr ##\n",
    "lr = 0.1\n",
    "weight_decay = 1e-4\n",
    "epochs = 160\n",
    "best_prec = 0\n",
    "\n",
    "#model = nn.DataParallel(model).cuda()\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay)\n",
    "#cudnn.benchmark = True\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "        \n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "thick-ready",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8348/10000 (83%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## check your accuracy again after finetuning\n",
    "\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "driving-tanzania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global sparsity for weight_int: 0.6982 (69.82%)\n"
     ]
    }
   ],
   "source": [
    "from models import QuantConv2d\n",
    "\n",
    "#### check global sparsity for weight_int is near 80% #####\n",
    "# Iterate through all QuantConv2d layers and compute weight_int sparsity\n",
    "\n",
    "w_bit = 4\n",
    "total_zeros = 0\n",
    "total_elements = 0\n",
    "\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, QuantConv2d):\n",
    "        weight_q = module.weight_q\n",
    "        w_alpha = module.weight_quant.wgt_alpha\n",
    "        w_delta = w_alpha / (2**(w_bit-1) - 1)\n",
    "        \n",
    "        weight_int = weight_q / w_delta\n",
    "        \n",
    "        zeros = (weight_int == 0).sum().item()\n",
    "        elements = weight_int.nelement()\n",
    "        \n",
    "        total_zeros += zeros\n",
    "        total_elements += elements\n",
    "\n",
    "global_sparsity = total_zeros / total_elements\n",
    "print(f\"Global sparsity for weight_int: {global_sparsity:.4f} ({global_sparsity*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "furnished-peeing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-firmware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity level:  tensor(0.9204, device='cuda:0')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "textile-cancer",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selected-excuse",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-auction",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-whole",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-significance",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exposed-witch",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "entitled-barbados",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-serbia",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
